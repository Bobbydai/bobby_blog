<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="第一遍看下来，感觉大部分是公式和矩阵计算之类的，transformer架构中每一个模块都有不同的计算公式和方法，给人看的懵懵的，不知道学习这个对AI的应用开发帮助是否大，只能说这块的学习是以了解一下，拓宽知识广度为目的。后面需要面试跳槽🐶，或者是工作中有对应需求的情况下再去深入理解。\n"><title>0617 Transformer学习</title><link rel=canonical href=https://bobbydai.github.io/bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/><link rel=stylesheet href=/bobby_blog/scss/style.min.946cca6c6259ef94ac55abfae7c7bf3291ea3ed5eea17ef77500b257217c6710.css><meta property='og:title' content="0617 Transformer学习"><meta property='og:description' content="第一遍看下来，感觉大部分是公式和矩阵计算之类的，transformer架构中每一个模块都有不同的计算公式和方法，给人看的懵懵的，不知道学习这个对AI的应用开发帮助是否大，只能说这块的学习是以了解一下，拓宽知识广度为目的。后面需要面试跳槽🐶，或者是工作中有对应需求的情况下再去深入理解。\n"><meta property='og:url' content='https://bobbydai.github.io/bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/'><meta property='og:site_name' content="Bobby's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:published_time' content='2025-06-17T10:54:53+08:00'><meta property='article:modified_time' content='2025-06-17T10:54:53+08:00'><meta name=twitter:title content="0617 Transformer学习"><meta name=twitter:description content="第一遍看下来，感觉大部分是公式和矩阵计算之类的，transformer架构中每一个模块都有不同的计算公式和方法，给人看的懵懵的，不知道学习这个对AI的应用开发帮助是否大，只能说这块的学习是以了解一下，拓宽知识广度为目的。后面需要面试跳槽🐶，或者是工作中有对应需求的情况下再去深入理解。\n"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/bobby_blog/><img src=/bobby_blog/img/bobby_hu_5ab7b01479abb835.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🐷</span></figure><div class=site-meta><h1 class=site-name><a href=/bobby_blog>Bobby's Blog</a></h1><h2 class=site-description>波比哈哈哈的博客</h2></div></header><ol class=menu-social><li><a href=https://github.com/Bobbydai target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/bobby_blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/bobby_blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/bobby_blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/bobby_blog/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/bobby_blog/categories/%E6%8A%80%E6%9C%AF/ style=background-color:#2a9d8f;color:#fff>技术</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/>0617 Transformer学习</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Jun 17, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 2 分钟</time></div></footer></div></header><section class=article-content><p>第一遍看下来，感觉大部分是公式和矩阵计算之类的，transformer架构中每一个模块都有不同的计算公式和方法，给人看的懵懵的，不知道学习这个对AI的应用开发帮助是否大，只能说这块的学习是以了解一下，拓宽知识广度为目的。后面需要面试跳槽🐶，或者是工作中有对应需求的情况下再去深入理解。</p><p>transformer整体流程结构：</p><p><img src=/bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/1.png width=1342 height=986 srcset="/bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/1_hu_ff1b7a8ab9c13c3a.png 480w, /bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/1_hu_c2c5cafa2c738bd6.png 1024w" loading=lazy class=gallery-image data-flex-grow=136 data-flex-basis=326px></p><p>流程:</p><p>1.将输入句子中每一个单词的位置embedding和词embeeding相加，组成一个transformer表示矩阵进行输入</p><p>2.将transformor表示矩阵输入到多个encoder中，最终转换成编码矩阵</p><p>3.将编码矩阵输入到多个decoder中，decoder会按顺序+mask（遮盖住还未经过decoder的输入矩阵），一行一行的将每个单词进行预测。</p><p>transformer内部结构</p><p><img src=/bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/2.png width=640 height=884 srcset="/bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/2_hu_cf778a5d726bb74.png 480w, /bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/2_hu_2b01c8b9d256f388.png 1024w" loading=lazy class=gallery-image data-flex-grow=72 data-flex-basis=173px></p><p>上图是论文中 Transformer 的内部结构图，左侧为 Encoder block，右侧为 Decoder block。红色圈中的部分为 Multi-Head Attention，是由多个 Self-Attention组成的，可以看到 Encoder block 包含一个 Multi-Head Attention，而 Decoder block 包含两个 Multi-Head Attention (其中有一个用到 Masked)。Multi-Head Attention 上方还包括一个 Add & Norm 层，Add 表示残差连接 (Residual Connection) 用于防止网络退化，Norm 表示 Layer Normalization，用于对每一层的激活值进行归一化。</p><p>self-attention 结构</p><p><img src=/bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/3.png width=406 height=488 srcset="/bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/3_hu_54f2f6d1ca747786.png 480w, /bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/3_hu_44babde796d48fc5.png 1024w" loading=lazy class=gallery-image data-flex-grow=83 data-flex-basis=199px></p><p>计算的的时候需要用到Q,K,V
本质上就是基于上面输入的transformer向量X做矩阵变换</p><p>得到Q,K,V之后用下面的公式进行计算
<img src=/bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/4.png width=1410 height=1328 srcset="/bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/4_hu_332d74df5fb75184.png 480w, /bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/4_hu_bda8c866b9ebaab7.png 1024w" loading=lazy class=gallery-image data-flex-grow=106 data-flex-basis=254px></p></section><footer class=article-footer><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><script src=//unpkg.com/@waline/client@v2/dist/waline.js></script><link href=//unpkg.com/@waline/client@v2/dist/waline.css rel=stylesheet><div id=waline class=waline-container></div><style>.waline-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding);--waline-font-size:var(--article-font-size)}.waline-container .wl-count{color:var(--card-text-color-main)}</style><script>Waline.init({avatar:"",dark:'html[data-scheme="dark"]',el:"#waline",emoji:["https://npm.elemecdn.com/@waline/emojis@1.1.0/bilibili","https://npm.elemecdn.com/@waline/emojis@1.1.0/bmoji","https://npm.elemecdn.com/@waline/emojis@1.1.0/weibo"],lang:"zh-CN",locale:{admin:"波比",placeholder:null,sofa:"还没有人评论哦！快来抢沙发吧~"},placeholder:"欢迎留下宝贵的评论！",requiredMeta:["name","email","url"],serverURL:"https://waline-delta-black.vercel.app",visitor:""})</script><footer class=site-footer><section class=copyright>&copy;
2025 Bobby's Blog</section><section class=powerby>么么哒<br>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/bobby_blog/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><script src=https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js></script><meting-js server=netease type=playlist autoplay theme=#ff0000 id=13850385353></meting-js></body></html>