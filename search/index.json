[{"content":" 您的浏览器不支持 video 标签。 您的浏览器不支持 video 标签。 ","date":"2025-06-20T21:46:16+08:00","permalink":"https://bobbydai.github.io/bobby_blog/p/0620-%E9%BB%84%E6%9E%9C%E6%A0%91%E7%80%91%E5%B8%83%E4%B8%80%E6%97%A5%E6%B8%B8/","title":"0620 黄果树瀑布一日游"},{"content":"今天很开心跟妈妈一起去了顺德的和艺术馆。和艺术馆是在顺德北滘附近，旁边就是美的的总部。美的也是我校招一开始想去的公司，去的话其实不是因为他这个公司有多么厉害，主要是因为他离家近嘛，他就在佛山。 因为当时想的如果去美的上班的话，我可以直接在澜石住从小就一直呆着的海景大厦然后每天可以上下班开着车，也只需要30分钟的一个路程 这样的生活也还是挺好的。可惜秋招的时候，我的简历上传了之后，他就再也没有理过我😂\n再回到那个艺术馆，其实艺术馆他这布局还是挺好玩的，然后整体也是非常有艺术的氛围。 在里面看到了很多油画，山水画，西洋画之类的。 另外里面的一些装饰还有材料都是非常美观的特别是整一个楼梯，它中间楼梯的一个布局还有往上面吊着的一个类似于吊灯之类的一个东西，一直在旋转给人的感觉还挺有意思的。 另外，除了去了和艺术馆，我还去了对面的一个also的一个商业街。这里面它其实是一些高端的一些店铺比较多，有点给人一种小资的感觉。而且它里面也有一个饭堂，一开始不知道为什么它的商业街里还有个饭堂。后面才发现原来它是连着美的的总部的，可能他们下班是来这个饭堂里面吃饭的。 最后逛了1圈也没有发现特别想去的一些餐厅因为里面都太高端了，所以不好意思去最后还是回了禅城吃啫啫煲，也挺好吃的。 ","date":"2025-06-18T21:13:21+08:00","permalink":"https://bobbydai.github.io/bobby_blog/p/0618-%E5%92%8C%E8%89%BA%E6%9C%AF%E9%A6%86%E9%A1%BA%E5%BE%B7%E4%B8%80%E6%97%A5%E6%B8%B8/","title":"0618 和艺术馆顺德一日游"},{"content":"未知和未来是一对双胞胎，一个在学习方面有天赋 另外一个在体育方面有天赋 未来考上了首尔大学。 未知则在体育高考中的跑步比赛里受伤了，梦想也破灭了。其实未知上不了大学之后也想去找工作，但是因为外婆重病住院，所以就一直照顾她，也因此放弃了自己的未来，天天干着零时工。未知则去了大城市上班，每个月将工资寄回家，压力也很大。 剧中未知曾有一段话，我会变成这样是因为我本来就是这样的人吗？还是因为我过的生活让我变成现在这样。 这句话还挺有意思的，我理解的话，其实两者都有吧。挺矛盾的也不太好说 我感觉还是生活对人的影响大吧，环境对一个人的影响会更大一点。 因为人刚出生下来，其实感觉很多东西都是不确定的。其实都是被环境所去影响去塑造的。 这里可以看出来，虽然未知特别有爱心，把自己的未来放弃了，而去照顾外婆，但我觉得在现实当中去。这种方法是不可取的。联想到现实，我也觉得就是说家里能帮的要帮，但是不应该让自己的未来被家庭所束缚，自己的方向还是要靠自己去掌握。不过，我顺便吐槽一句：看了这么多韩剧。每一个剧里面都有很多演员似曾相识的，特别脸熟😂。\n还有一个男主男浩珠,浩珠学习成绩也很好，然后是未来跟位置的邻居高中的时候。 其实刚来的时候，他是也是挺高冷的。但是学习也挺好的跟未来一直是第一第二，高中的时候也在一起谈恋爱，但其实看起来其实浩朱好像是喜欢未知的，这个也不确定往后面慢慢看吧。\n我早剧情真有意思吧我说实话。\n第二集也好看哎，但是看到现在还是不清楚男主到底喜欢谁。但是中间穿插的一些回忆还挺有意思的，这种叙事方式我还比较喜欢，起码容易看懂，不像有些韩剧在前几集埋个伏笔，在最后一两集才回应一下，不看弹幕都不知道这是伏笔哈哈哈哈。另外这个剧情没啥问题，但是像我这种比较怕尴尬的人是真的看一会儿就得暂停一下hhh，但是女主男主确实都挺好看的哈哈哈哈，很难忍住不看下去。\n自我中心这段是真的蚌埠住了，未知跟未来学的哈哈哈\n快要看完第二集了第二集比较感动的一段是未来代替未知去看外婆的时候。 这一段外婆直接认出了未来，然后未来也袒露了自己的心声说自己工作压力太大了，决定放弃了 这个想法也得到了外婆的理解,还是挺感动的.\n有点甜啊hhh\n看到第四集了，感觉还是挺有意思的，感觉姐妹和男主都是在从迷茫中找寻自己。\n人生就像草莓，就算现在尝起来太酸，但用酸草莓也能做出最好的果酱\n啊啊啊啊啊啊!!!!! 原来未知真的是浩朱的初恋啊，这下误会真大了hhh，经典韩剧全是误会。\n有点甜hhhh\n写错人了哈哈哈哈 ","date":"2025-06-17T15:15:48+08:00","permalink":"https://bobbydai.github.io/bobby_blog/p/0617-%E6%9C%AA%E7%9F%A5%E7%9A%84%E9%A6%96%E5%B0%94/","title":"0617 未知的首尔"},{"content":"第一遍看下来，感觉大部分是公式和矩阵计算之类的，transformer架构中每一个模块都有不同的计算公式和方法，给人看的懵懵的，不知道学习这个对AI的应用开发帮助是否大，只能说这块的学习是以了解一下，拓宽知识广度为目的。后面需要面试跳槽🐶，或者是工作中有对应需求的情况下再去深入理解。\ntransformer整体流程结构：\n流程:\n1.将输入句子中每一个单词的位置embedding和词embeeding相加，组成一个transformer表示矩阵进行输入\n2.将transformor表示矩阵输入到多个encoder中，最终转换成编码矩阵\n3.将编码矩阵输入到多个decoder中，decoder会按顺序+mask（遮盖住还未经过decoder的输入矩阵），一行一行的将每个单词进行预测。\ntransformer内部结构\n上图是论文中 Transformer 的内部结构图，左侧为 Encoder block，右侧为 Decoder block。红色圈中的部分为 Multi-Head Attention，是由多个 Self-Attention组成的，可以看到 Encoder block 包含一个 Multi-Head Attention，而 Decoder block 包含两个 Multi-Head Attention (其中有一个用到 Masked)。Multi-Head Attention 上方还包括一个 Add \u0026amp; Norm 层，Add 表示残差连接 (Residual Connection) 用于防止网络退化，Norm 表示 Layer Normalization，用于对每一层的激活值进行归一化。\nself-attention 结构\n计算的的时候需要用到Q,K,V 本质上就是基于上面输入的transformer向量X做矩阵变换\n得到Q,K,V之后用下面的公式进行计算 ","date":"2025-06-17T10:54:53+08:00","permalink":"https://bobbydai.github.io/bobby_blog/p/0617-transformer%E5%AD%A6%E4%B9%A0/","title":"0617 Transformer学习"},{"content":"今天先打个分吧，今天可以给自己打个8分吧满分十分。 因为我今天说实话，就相比前几天刚回家的时候没有那么浑浑噩噩了，今天还是做挺多事情的因为前两天的话呢？突然就是有了这个想法，做一个博客的感觉嘛，突然有这个想法，所以今天呢，这两天一直想把它给落地下来。然后经过这两天的一个努力终于是把它给落地了。感觉还是挺好的就是目前做到现在。我把那个音频啊，各个框架还有它的一个主题啊，等其他的功能都给做下来了，现在就还缺了一个那个pjax嘛。就是你跳不同的页面时候，它音乐会自己停。相当于要做这个功能，它这个功能是比较麻烦的所以说我现在想的这个 feature，就是还是先放在后面吧，然后呢还缺了一些后面就是一些美化的一些东西吧。就是做一些动态的一些鼠标啊，各种的玩偶。那些也都不是那个必要的一些东西就优先级可以放低一点嘛，就我们现在想的还是先把这个博客先开始慢慢做起来吧，就每天的一个日记啊，把它给做出来对 这样的话，你才能把这个博客，这个内容给它做丰富一些嘛，但是后面的话呢，就是还会考虑到一个隐私性的问题就是说我们，我写的这个日记这一块呢，可能不能给别人看。 然后呢，其他的东西是可以看的对所以这一块可能是要用到那个hidden的那个配置，但是那个配置你，你用了的话你可能要把那个分类又给又得给去掉所以就还是挺不好弄就是说不好弄还得明天得看一下，因为这个得早点做决定嘛，不然，你后面，你慢慢日记做的越来越多的时候你到时候你想再把这个博客也放出去给别人看的时候你就没有办法去做了嘛，你想重新再去重构的话，就有点麻烦 对所以说，这2天的话，主要还是先把这个东西这个优先级是放在第一位，其他的那些小 feature就是后面有空再去做吧，先接下来这个博客就先到此为止吧，就是第一版可以先做到这样，我觉得还是挺满意的对我们把那个音乐给他接入了然后呢这个 vs code，他的一个语音输入我也收到了这个插件就把这个插件给用起来了，所以现在用语音收入还是挺好玩的。 对然后后面想一想，就是先看看书吧，好好看书然后呢 对把书先看好然后呢，把那个ai那些学习的东西把它给继续学下去，然后另外的话呢，就是说那个作业的问题啊，作业我们还差了几个实验报告所以有点搞笑啊，就是我想的就是。 看明天再看一眼嘛，看有什么能先做的，然后呢？等22号回去之后再好好开始做吧，花 23天给他补补完吧，我感觉回去可能时间也挺紧的所以说，这 2天还是先做一下尽量做一些就做一些不要把那个回学校的那个时间给他压的太死了对。 对大概就是先这样吧 对这2天的话呢？还是需要把睡觉，给弄好一点，因为我刚刚回来感觉就非常难受啊，就是几天就睡觉，都睡不好，然后现在爷爷奶奶走了之后，反而还睡觉睡好了一点好吧，我现在还是把睡眠先放在第一位然后的话呢，皮肤也要注意对其实还是挺多事情的就先这样吧，先这样吧，先这样吧好吧。 今天第一篇日记用语音输入的等会再改改。\n","date":"2025-06-17T00:02:37+08:00","permalink":"https://bobbydai.github.io/bobby_blog/p/0617-%E6%94%BE%E5%81%87%E5%BC%80%E5%BF%83%E7%9A%84%E4%B8%80%E5%A4%A9/","title":"0617 放假开心的一天"},{"content":"螣龙安科实习\n实习拷打：\n为什么实习项目用到了django框架 有个AI的底层服务用到了python的框架\n用的什么框架，gin框架有哪些特性，你用到了哪些\n答了gin的context 自带log+recovery中间件 路由的前缀树，高性能\n还有：对JSON的解析和验证，渲染前端，设置静态资源目录，自定义中间件\n还有种骚操作就是可以修改gin上下文的参数然后直接跳到另外一个service里面去\nGin可以渲染前端吗？\n可以，使用Go的html/template，还可以设置静态文件目录，用来提供前端应用的JavaScript、CSS和图片等资源文件。\n实习中用到了kafka，为什么使用kafka，kafka为什么消费数据这么快\nKafka天生的分布式架构：kafka集群里有多台服务器，每一台服务器就是一个broker，一个broker里面还有多个topic，一个topic可以放到多个broker里面，每个topic里面还有多个partition分区。 每个分区里存放数据的是log，kafka对log文件进行了分segment，并对segment建立了索引 对于单节点使用了顺序读写，顺序读写是指的文件的顺序追加，减少了磁盘寻址的开销，相比随机写速度提升很多 使用了零拷贝技术，不需要切换到用户态，在内核态即可完成读写操作，且数据的拷贝次数也更少。 讲一下redis的消息队列怎么使用 mq 分为 push 型和 pull 型 缺点： 内存是易失性存储，数据容易丢失，主从切换时数据存在弱一致问题\n第一种：redis 中的 list 结构. Lpush BRpop(brpop是list中有数据才返回的，这样可以减少资源消耗) 缺点：无法支持一对多的发布订阅模式 消费端没有ACK机制\n还有redis pub/sub和stream两个模式，他们支持发布订阅，streams模式是最好的，但还有一个开源的redis分布式消息队列asynq，他的优点有：\n任务持久性：asynq保证每个任务至少被消费一次，即便在消费过程中出现失败，它也支持重试机制，这比基于list的方式更能确保任务的可靠性 。 延时队列支持：asynq支持延时任务，可以指定任务在特定时间后执行，这是简单list实现所不具备的 。 高可用性：asynq支持Redis集群和哨兵模式，这为使用asynq的系统提供了高可用性保证 。 消费监控：asynq自带完善的监控功能，方便追踪任务状态和性能监控，而简单的list实现则缺少这种内建的监控和管理功能 。 灵活的配置选项：asynq允许配置多个具有不同优先级的队列，并支持批量消费任务，提供了更多的灵活性和控制能力 。 简化的API设计：asynq提供了简单明了的API，简化了任务的创建、发送和消费过程 。 redis的持久化 AOF和RDB\nAOF 文件的内容是操作命令； RDB 文件的内容是二进制数据 RDB一般是使用save和bgsave来执行，这两个的区别是save在主线程，bgsave在子线程，如果写入 RDB 文件的时间太长，会阻塞主线程，所以还是开一个子线程吧 一般都是在redis里面进行配置，每隔一段时间记录一次快照，但这样两次记录间隔时间内redis宕机了就会丢失数据，相对AOF来说数据丢失的更多\nRDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以 AOF恢复数据则需要一条一条按顺序执行命令\nAOF只会记录写操作命令，读操作命令是不会被记录的\nAOF和RDB的应用场景分别是什么\nRDB的应用场景： 适合做数据备份和灾难恢复，因为它会生成数据的快照，可以方便地存储或迁移数据 。 适合在数据集较大时使用，因为RDB文件读取速度较快，可以更快地启动Redis服务器 。 适合对数据安全性要求不是特别高的场景，因为RDB可能在最后一次备份后的数据变更中存在丢失的风险 。 AOF的应用场景： 适合对数据安全性要求较高的场景，AOF记录了所有的写操作命令，可以提供更高的数据安全性 。 适合用于数据的完整性和一致性要求较高的业务，因为AOF可以减少数据丢失的风险，最多只会丢失一秒钟的数据 。 go的channel讲一下 channel是啥 channel读跟写的操作\nGo 的gmp讲一下 线程是内核态的，协程跟线程是多对一的关系，一个线程里面的协程无法并行\nGoroutine，经 Golang 优化后的特殊“协程”，核心点如下： （1）与线程存在映射关系，为 M：N； （2）创建、销毁、调度在用户态完成，对内核透明，足够轻便； （3）可利用多个线程，实现并行； （4）通过调度器的斡旋，实现和线程间的动态绑定和灵活调度； （5）栈空间大小可动态扩缩，因地制宜\ngo有原子操作嘛 有，atomic包\n除了加加减减原子操作还能拿来干嘛\n状态标志：使用原子操作设置和检查状态标志，例如初始化完成、关闭请求等。 引用计数：在需要手动管理内存的场合，可以使用原子操作来增加和减少引用计数，确保资源在不再使用时被正确释放。 并发队列：使用原子操作实现无锁的队列，确保生产者和消费者之间的同步。 条件变量：原子操作可以用来实现条件变量，例如自旋锁或条件等待，直到某个条件成立。 序列号生成：生成唯一的序列号或时间戳，确保在分布式系统中的唯一性。 累加器：在聚合计算中，可以使用原子操作来更新共享的累加器，如求和、平均值等。 并发控制：在限制并发执行的goroutine数量时，可以使用原子操作来控制并发级别。 缓存行同步：在性能敏感的应用中，使用原子操作来同步缓存行的状态，避免缓存一致性问题。 无锁数据结构：构建无锁的数据结构，如无锁栈、队列、链表、哈希表等。 竞态条件检测：在调试并发程序时，可以使用原子操作来检测和诊断竞态条件。 分布式计数器：在分布式系统中，使用原子操作来同步多个节点上的计数器。 选举算法：在某些分布式一致性算法（如Raft）中，原子操作可以用于领导者选举。 屏障（Barrier）：实现线程屏障，等待多个goroutine到达某个点后再继续执行。 原子比较和交换（CAS）：实现复杂的同步逻辑，如循环中的自旋锁。 发布-订阅模式：在实现发布-订阅模式时，使用原子操作来管理订阅者列表。 原子操作和锁有啥区别，哪个性能消耗低一点 原子操作低一点：原子操作是通过硬件支持的原子指令来实现的，它们保证了一个或多个操作在执行过程中不会被其他线程中断\n锁的性能消耗相对较高，因为它们可能涉及到线程的挂起和唤醒，这些操作需要操作系统的介入\nmysql建表时候的索引优化 前缀索引优化: 建立索引时使用字段的前几个字符建立索引。 目的：减少索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度\norder by 就无法使用前缀索引； 无法把前缀索引用作覆盖索引； 覆盖索引优化： 覆盖索引指的是sql中查询的字段二级索引（只记录索引列的数据）全都有，不需要回表 建立联合索引，里面带上需要查的字段\n主键索引最好是自增的： 插入一条新记录，都是追加操作，不需要重新移动数据 还可能会造成页分裂。页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率\n索引最好设置为not null： 索引列存在 NULL 就会导致优化器在做索引选择的时候更加复杂，更加难以优化 NULL 值是一个没意义的值，但是它会占用物理空间\nmysql执行update一条语句的时候mysql做了什么（innodb引擎） 执行器执行，调用存储引擎的接口，通过主键索引获取id=这一行 记录不在buffer pool就把数据页从磁盘读入到buffer pool。返回记录给执行器\nmysql查询怎么优化 防止索引失效：\n一个select,两个chan有缓冲有数据，先读哪一个\n算法：回文子串 双指针a了\n七牛云实习一面（疯狂拷打项目）\n讲一下你的实习公司的AI助理项目 1.使用场景，怎么赚钱？\n2.整体的架构，每个服务的作用是啥 B端：商家管理台，AI创作平台，商家配置机器人，AI广场，机器人商品信息。。。 C端：用户移动端，网页版对话界面（权益判断，流式非流式对话接口，对话记录。。。）\nai-core平台层：文生文，对话，文本向量化，工具插件调用\n3.每个服务你干了什么 B端：机器人配置放开给商家，机器人接入商品，AI创作平台（文生图？），数据导出，智库支持标准问答。。。 用到了流式响应SSE+轮询\nC端：用户对话记录，改的比较少\n4.具体重点和细节 流式对话 多路召回+重排 标准问答\nAI内容美化，课程标题封面这些指的是啥，怎么实现的 我们会有一个后端开发工程师专门针对不同的场景配一些提示词，我们要做的就是根据商家传入的课程介绍/节日祝福/视频标题的内容组装提示词一起发给下游AI能力平台，这个平台的文生文接口就调用对应的大模型来进行帮他回复\n了解向量数据库这块吗 向量数据库主要用来存储和处理向量数据。图像、文本和音视频都可以转化为向量数据存储到向量数据库中\n图像：其实是一个二维矩阵，直接转成向量数据 视频：图像+时间维度，三维矩阵 音频：先转文本再转向量\n向量数据库es的能力： 相似度计算：余弦距离，欧式距离，点积 检索：暴力计算，近似最近邻搜索算法\n流式响应讲一下，有哪些实现方式 SSE 轮询\n流式前端处理还是后端处理 主要是后端\n知识库存在哪，业务层有存吗 es\n音视频内容怎么转成知识库 也转成智能字幕，文本的形式，再去存入es中\n如果你开三个子线程，使用了内容插件但是问题跟插件毫无关系怎么办，还要走这边嘛 这个只能靠大模型自己了，这个工具插件是在机器人维度配置的，一般就只有转人工，课程推荐和图片识别，商家可以设置开关。\nSSE跟http有什么关系\nSSE（Server-Sent Events）与HTTP的关系非常紧密，具体如下：\n基于HTTP协议：SSE是建立在HTTP协议之上的技术。它使用HTTP协议的持久连接特性，允许服务器推送实时信息到客户端。 单向通信：与WebSocket等双向通信技术不同，SSE主要用于实现服务器到客户端的单向数据流。客户端通过HTTP连接订阅服务器上的事件源，服务器随后可以向这个连接推送消息。 MIME类型：SSE在发送数据时，服务器响应的MIME类型是text/event-stream，这表明数据将作为一个事件流发送。 连接保持：SSE利用HTTP连接保持活动状态，服务器可以在任何时候发送数据到客户端，而客户端则持续监听这些数据。 自动重连：如果连接断开，大多数浏览器实现的SSE会自动尝试重连，这是通过在请求头中包含Last-Event-ID来实现的，它指示服务器从哪个点继续发送事件。 简单实现：与WebSocket相比，SSE在客户端和服务器端的实现都比较简单，因为它不需要特殊的协议支持，只需要标准的HTTP服务器配置。 与HTTP/2的关系：在使用HTTP/2时，SSE的优势更加明显，因为HTTP/2支持多路复用（multiplexing），允许在单个TCP连接上并行传输多个SSE流，这提高了传输效率。 为什么有dify了还要用django框架 了解http2.0吗，http2.0也可以实现服务端主动推送的哦 确实可以，这个是http2.0的一个新功能，比如说当客户端请求一个资源（例如HTML页面）时，服务器可以预测客户端可能还需要的其他资源（如CSS、JavaScript文件或图片等），并通过PUSH_PROMISE帧将这些资源推送给客户端\nHTTP/2.0 的服务器推送功能与SSE（Server-Sent Events）不同。SSE是一种允许服务器向客户端单向推送实时数据的技术，通常用于实现如股票价格更新、实时通知等功能。SSE基于HTTP协议，使用文本格式的数据流，而服务器推送则是HTTP/2.0协议的一部分，可以推送任意类型的资源，并且使用二进制格式进行数据传输，更加高效 go怎么去实现SSE，是只用加个请求头就行了吗 c.Header(\u0026ldquo;Content-Type\u0026rdquo;, \u0026ldquo;text/event-stream\u0026rdquo;) c.Header(\u0026ldquo;Cache-Control\u0026rdquo;, \u0026ldquo;no-cache\u0026rdquo;)\nc.Header(\u0026ldquo;Connection\u0026rdquo;, \u0026ldquo;keep-alive\u0026rdquo;) c.Header(\u0026ldquo;Transfer-Encoding\u0026rdquo;, \u0026ldquo;chunked\u0026rdquo;) c.Header(\u0026ldquo;X-Accel-Buffering\u0026rdquo;, \u0026ldquo;no\u0026rdquo;)\n// 向上下文中写入响应内容 func writeResp2Writer(c *gin.Context, content string) error { if _, err := c.Writer.WriteString(content); err != nil { providers.DefaultLogger.Error(\u0026ldquo;流式响应写入上下文失败\u0026rdquo;, zap.Any(\u0026ldquo;err\u0026rdquo;, err), zap.Any(\u0026ldquo;respStr\u0026rdquo;, content)) return err } c.Writer.Flush() return nil }\nline, err := streamBody.ReadBytes(\u0026rsquo;\\n\u0026rsquo;) content := string(line)\n实习过程中dify框架的模型接入讲一下 开源+工厂模式\n标准问答是如何实现的 机器人配置一个阈值和知识集，AI平台能力层进行相似度检索和全文检索+重排得到一个得分最高的知识，如果分数超过给定的阈值就直接返回对应的答案。\n算法：二叉树的层序遍历：自底向上 （代码写完层序遍历之后想不到怎么按自底向上遍历卡了一下，后面说直接双指针左右两边交换一下，代码运行还有bug，但他就说ok了）\n后续：面试完十分钟后HR就说过了，下周二面\n七牛云实习二面（疯狂拷打项目+八股，50分钟无算法）\n上一段实习已经离职了吗，为什么离职 产品走了两个，目前没啥业务了（笑死） 哪一个项目你印象最深刻，讲一下 小鹅AI助理，具体思路看一面 具体的接口参数细节讲一下 主要介绍AI平台层的文生文和对话接口的参数 对话接口： { \u0026ldquo;app_id\u0026rdquo;: \u0026ldquo;appxssxqrfi3049\u0026rdquo;, \u0026ldquo;user_id\u0026rdquo;: \u0026ldquo;b_u_61d8fa0c60950_lrLLlk9f\u0026rdquo;, \u0026ldquo;robot_id\u0026rdquo;: \u0026ldquo;6490723440\u0026rdquo;, \u0026ldquo;message_id\u0026rdquo;: \u0026ldquo;09a280f8-5399-11ef-a902-8ee6968696df\u0026rdquo;, \u0026ldquo;business_scene_id\u0026rdquo;: \u0026ldquo;app\u0026rdquo;, \u0026ldquo;model_name\u0026rdquo;: \u0026ldquo;qwen-turbo\u0026rdquo;, \u0026ldquo;embedding_model_name\u0026rdquo;: \u0026ldquo;bge-large-zh-v1.5\u0026rdquo;, \u0026ldquo;prompt_variables\u0026rdquo;: { \u0026ldquo;reject_msg\u0026rdquo;: \u0026ldquo;很抱歉，我还没有学会这个问题，请您提供更多详细信息或尝试重新提问。\u0026rdquo;, \u0026ldquo;robot_name\u0026rdquo;: \u0026ldquo;AI助手\u0026rdquo;, \u0026ldquo;self_intro\u0026rdquo;: \u0026ldquo;你是一个AI助手\u0026rdquo;, \u0026ldquo;task_setting\u0026rdquo;: \u0026ldquo;你拥有以下技能：\\n1、功能咨询。\\n2、文案优化，根据提供的信息完成文案写作工作。\u0026rdquo; }, \u0026ldquo;knowledge_retriever\u0026rdquo;: \u0026ldquo;xiaoe_business_assistant\u0026rdquo;, \u0026ldquo;question\u0026rdquo;: \u0026ldquo;你是谁呀\u0026rdquo;, \u0026ldquo;image_url\u0026rdquo;: \u0026ldquo;\u0026rdquo;, \u0026ldquo;knowledge_base_ids\u0026rdquo;: [ 111 ], \u0026ldquo;top_k\u0026rdquo;: 10, \u0026ldquo;chat_history\u0026rdquo;: null, \u0026ldquo;similar_filter_score\u0026rdquo;: 0.3, \u0026ldquo;fallback_to_llm\u0026rdquo;: true, \u0026ldquo;tools\u0026rdquo;: null, \u0026ldquo;llm_parameters\u0026rdquo;: { \u0026ldquo;temperature\u0026rdquo;: 0.5, \u0026ldquo;stream\u0026rdquo;: true, \u0026ldquo;top_p\u0026rdquo;: 0.1 }, \u0026ldquo;image_model_name\u0026rdquo;: \u0026ldquo;glm-4v\u0026rdquo;, \u0026ldquo;faq_filter_score\u0026rdquo;: 0.5 }\n文生文：\n{ \u0026ldquo;model_config\u0026rdquo;: { \u0026ldquo;model_arr\u0026rdquo;: [ \u0026ldquo;abab6.5s-chat\u0026rdquo; ], \u0026ldquo;business_scene_id\u0026rdquo;: \u0026ldquo;test\u0026rdquo; }, \u0026ldquo;llm_parameters\u0026rdquo;: { \u0026ldquo;model_parameters\u0026rdquo;: { \u0026ldquo;temperature\u0026rdquo;: 0.8, \u0026ldquo;max_token\u0026rdquo;: 500 }, \u0026ldquo;stream\u0026rdquo;: true }, \u0026ldquo;prompt_list\u0026rdquo;: [ { \u0026ldquo;role\u0026rdquo;: \u0026ldquo;user\u0026rdquo;, \u0026ldquo;content\u0026rdquo;: \u0026ldquo;臣亮言：先帝创业未半而中道崩殂，13245678011今天下三分，益州疲弊，此诚123456789012345危急存亡之秋也。然侍卫之臣不懈于内，忠志之士忘身于外者，盖追先帝之殊遇，欲报之于陛下也。诚宜开张圣听，以光先帝遗德\u0026rdquo; } ], \u0026ldquo;chat_history\u0026rdquo;: [ { \u0026ldquo;role\u0026rdquo;: \u0026ldquo;user\u0026rdquo;, \u0026ldquo;content\u0026rdquo;: \u0026ldquo;你好\u0026rdquo; }, { \u0026ldquo;role\u0026rdquo;: \u0026ldquo;assistant\u0026rdquo;, \u0026ldquo;content\u0026rdquo;: \u0026ldquo;你好吖\u0026rdquo; } ] }\n如果有一个亿级的数组，要去遍历查里面某一个数，怎么办\n将数组元素作为键放入哈希表中，可以极大提高搜索效率。 搜索时间复杂度：O(1)。 空间复杂度：O(n)。 为数组建立索引结构，如倒排索引，可以快速定位数值所在范围\n利用多核处理器的并行计算能力，将数组分割成多个块，每个核心处理一个块，可以显著减少查找时间。\n使用布隆过滤器可以快速判断一个元素是否不存在于数组中，但有一定的误判率。\n将数据存储在数据库中，并利用数据库的索引来加速查找过程\n在分布式系统中，数据可以分布在多个节点上，每个节点负责一部分数据的查找，然后汇总结果。\nC端用户可以选择提问的模型嘛 不能 如果模型回答效果不好怎么切 人工切，肉眼看回答效果 有没有自动化切模型的方法,就回复效果不好的情况下（开放题） 目前由于体量比较小，所以我们基本就是建群，肉眼看回答效果，后期可能会考虑使用一些机器学习，或者是某些评估方法（之前弄数学建模搞过什么主成分分析法之类的）来评估模型的一个回答效果的好坏，目前还没有这个计划。\nmysql的隔离等级 脏读 不可重复读 幻读\n对话记录有存嘛，存在哪，存储的格式是怎么样的 数据库 问题和回答，回答的类型，提问的场景之类的\n如果业务变大对话记录要从100张表分成1000张表怎么办 跑脚本，再多就分库分表\n如果对话记录过多，并发量越来越大，mysql顶不住了怎么办 转到es和hbase里面\nhbase和es为什么适合大数据，查询速度快，底层架构了解吗 HBase和Elasticsearch（ES）都是处理大数据的利器，它们在不同的场景下展现出各自的优势。 HBase 是一个分布式的、可扩展的大数据存储系统，它基于Google的BigTable模型，运行在Hadoop的HDFS之上。HBase适合存储非结构化或半结构化的大数据，它的特点是：\n列式存储：HBase按列族存储数据，这样可以只读取需要的列族，而不是整行数据，从而提高查询效率。 自动分片：HBase表在物理上会分成多个区域（Region），每个区域可以独立查询，这样可以并行处理大量数据。 高可靠性：HBase的数据存储在HDFS上，可以利用HDFS的高可靠性和容错能力。 高性能：HBase支持快速读写，尤其是在数据模型、数据压缩、数据分区等方面具有优势。 Elasticsearch 是基于Lucene的搜索引擎，它提供了分布式多租户能力的全文搜索引擎，具有HTTP web接口和无模式JSON文档的特点。ES的优势在于： 实时搜索：ES提供了快速的搜索能力，适合实时数据分析。 分布式架构：ES的集群可以自由扩缩容，数据以索引、分片的形式散列在各个节点上，提高了查询性能。 索引优化：ES支持多种索引类型，如普通索引、倒排索引等，可以通过索引优化提高查询效率。 灵活的查询：ES具有丰富的查询DSL，可以执行复杂的查询操作。 在底层架构上，HBase由HMaster、RegionServer和ZooKeeper等组件构成，支持横向扩展，通过增加廉价的商用服务器来增加计算和存储能力。而Elasticsearch的架构包括主节点（master nodes）、数据节点（data nodes）和功能节点（ingest, ml, remote_cluster_client, transform 等），它的分布式架构允许水平扩展，并且支持分组定向路由和主从分片物理复制，提高了写入性能。 redis哨兵机制，有自己在本地实现过吗\n分布式raft算法了解吗，讲一下 Raft算法是一种用于分布式系统中的一致性协议，它以易于理解和实现著称。Raft算法的核心是在一个分布式系统中选举出一个领导者（Leader），然后由该领导者负责处理所有客户端请求，并将请求以日志条目（Log Entry）的形式复制到集群中的所有节点，确保数据的一致性。 Raft算法的工作流程大致可以分为以下几个步骤：\n领导者选举（Leader Election）：当系统启动或者当前领导者失效时，Raft算法会开始一个新的领导者选举过程。每个节点开始时都是追随者（Follower），如果在设定的选举超时时间内没有收到来自领导者的心跳，它就会变成候选人（Candidate）并开始新的领导者选举。候选人会增加自己的任期（Term）并给自己投票，然后请求其他节点的选票。如果一个候选人获得了大多数节点的投票，它就会成为新的领导者。 日志复制（Log Replication）：一旦选举出领导者，客户端的请求就会被发送到领导者。领导者接收到请求后，会将请求以日志条目的形式添加到本地日志中，然后并行地将这个日志条目发送给其他追随者节点。只有当日志条目在大多数节点上都被复制成功后，领导者才会将该条目应用到自己的状态机，并向客户端返回成功响应。 安全性保证（Safety）：Raft算法通过一系列的安全性机制保证了强一致性。例如，一个写请求只有在被提交后才能被其他节点响应，保证了写入的持久化。另外，Raft算法还具有日志匹配和状态机安全等机制，确保即使在节点发生故障的情况下，系统状态依然保持一致。 成员变更（Membership Changes）：Raft算法也支持集群成员的动态变更，即允许在不停机的情况下添加或移除节点。 Raft算法的优势在于它的易理解性和实现的简洁性，同时它也提供了高可用性和强一致性的保证。它在实际应用中得到了广泛的应用，例如在分布式数据库、云计算和区块链等领域都有应用。 Raft算法的实现通常包括以下几个关键组件： 心跳机制：领导者定期向追随者发送心跳以维持其领导地位，并防止追随者超时并开始新的选举。 日志匹配原则：在复制日志时，领导者会确保追随者的日志与自己的日志保持一致。 提交规则：只有当日志条目被复制到大多数节点上时，该日志条目才会被提交。 Raft算法的实现保证了在面对网络分区、节点故障等异常情况下，系统仍然能够保持一致性 多个服务的bug你是怎么排查的 日志，链路追踪 如果是内存泄漏这种情况看日志看不了怎么办 gpprof\n有数据集训练的经验吗，AI大模型的背后有使用哪些技术了解吗 无，爬\n是全部用别的厂商的模型还是有自研的模型 别的，小鹅通没钱自研\n阶段性总结一下：第二段实习找了大概9天左右，共投递十五家左右，面试3家，总共面了两家就找到实习了，真的很幸运，也说明自己的努力是有用的哈哈\n1.面经一定要多看，因为公司都有一个题库的，很多问的八股都是一样的，另外面试先可以刷一下面经里考的算法找手感\n2.目前项目优先级是第一位，不会的可以多问下钊哥，看看代码，AI助理这块项目肯定是要留着先得，然后把代码存下来多看看，RPA这块可以先放一下，后期项目应该会再放一个七牛云实习的项目\n3.八股：go，计网，操作系统，redis，mysql，kafka（稍微了解一下），es（稍微了解一下），hbase（稍微了解一下），目前还剩mysql和redis一轮没过，准备把这两个看完之后准备二轮\n4.场景题可以多看一下网上的面经找找感觉\n5.算法目前119力扣+15牛客总共134题 目前除了动态规划+贪心+堆其他基本都过了一遍的 接下来打算从代码随想录的动态规划开始学起，然后定期去继续刷力扣100把，大概是这么多。\n另外就是笔记和算法一定要做好归纳分类，不然现场辅助面试的时候也找不到。\n目标规划： 9月9号前把简历写好然后全国开投，目前还有12天自己的时间，得继续加油哈哈哈。\n补充：主要精力放在go+AI方向，其他的实在没办法再投试试看。\nB站服务端实习一面\n项目只问了五分钟，了解了一个核心接口就没了（面试官甚至还没理解我说的逻辑，水平感觉一般般难绷）\nQPM（每分钟请求数）多少， QPS（每秒请求数）呢\n写代码的时候有没有遇到什么坑 Panic 代码题：用go实现一个简单的协程池，写完之后 package main\nimport ( \u0026ldquo;fmt\u0026rdquo; \u0026ldquo;runtime\u0026rdquo; \u0026ldquo;sync\u0026rdquo; \u0026ldquo;time\u0026rdquo; )\n// 定义goroutine池 type GoroutinePool struct { queue chan func() wg sync.WaitGroup }\n// 创建一个新的goroutine池 func NewGoroutinePool(size int) *GoroutinePool { pool := \u0026amp;GoroutinePool{ queue: make(chan func(), size), // 缓冲区大小为goroutine池大小 }\npool.wg.Add(size) for i := 0; i \u0026lt; size; i++ { go pool.worker() } return pool }\n// 启动一个goroutine来处理任务 func (p *GoroutinePool) worker() { defer p.wg.Done() for f := range p.queue { f() } }\n// 提交任务到goroutine池 func (p *GoroutinePool) Submit(f func()) { p.queue \u0026lt;- f }\n// 关闭goroutine池，不再接受新任务 func (p *GoroutinePool) Close() { p.wg.Wait() close(p.queue) }\n// 测试goroutine池 func main() { pool := NewGoroutinePool(runtime.NumCPU()) // 根据CPU核心数创建goroutine池\nfor i := 0; i \u0026lt; 20; i++ { task := func(id int) { fmt.Printf(\u0026quot;Task %d is running on goroutine %d\\n\u0026quot;, id, runtime.CurrentGoroutine()) time.Sleep(100 * time.Millisecond) // 模拟任务执行时间 } pool.Submit(task) } // 等待所有goroutine完成 pool.Close() fmt.Println(\u0026quot;All tasks have been processed.\u0026quot;) } 还问了阻塞和无阻塞的情况，这里写的还行\n算法一：力扣154，复杂链表的复制 没做过这题，做了一半没理解要干嘛，说要不换一道\n方法一：hashmap，map中存的是（原节点-\u0026gt;新节点）的映射关系（方法二有点巧妙，就是复制链表节点，感觉一般人想不到的，第一种比较简单一点） 时间复杂度：O(n) 2次遍历 空间复杂度：O(n)\n/**\nDefinition for a Node. type Node struct { Val int Next *Node Random *Node } */ func copyRandomList(head *Node) *Node { if head == nil { return nil } // map中存的是（原节点-\u0026gt;新节点）的映射关系，此时新节点只有val，指针并没有安排上 m := make(map[*Node]*Node) for cur := head; cur != nil; cur = cur.Next { m[cur] = \u0026amp;Node{Val: cur.Val} } // 将新节点串起来，组成新链表 for cur := head; cur != nil; cur = cur.Next { m[cur].Next = m[cur.Next] m[cur].Random = m[cur.Random] } return m[head] } 链接：https://leetcode.cn/problems/fu-za-lian-biao-de-fu-zhi-lcof/solutions/994069/jian-zhi-offer-35-fu-za-lian-biao-de-fu-1iud0/ 来源：力扣（LeetCode） 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 算法二：二叉树转成链表（按照先序遍历全部堆到右链表） 比较简单但做到最后没调试出来有bug，当时快一个小时了人有点晕了 做法一：空间复杂度为O（n） func flatten(root *TreeNode) { if root==nil{ return } var list []*TreeNode var traverse func(root *TreeNode) traverse = func(root *TreeNode) { if root == nil { return } list = append(list, root) traverse(root.Left) traverse(root.Right) } traverse(root) head := list[0] // 链表的头应该指向第一个节点 for i := 1; i \u0026lt; len(list); i++ { head.Left = nil // 扁平化后左子节点应该为nil head.Right = list[i] // 设置右子节点 head = head.Right // 更新head为当前节点的右子节点 } } 做法二：空间复杂度为O（n），直接在原树上面改，有点难想的 func flatten(root *TreeNode) { if root == nil { return } cur := root for cur!= nil { if cur.Left != nil { next := cur.Left prenext:=next for prenext.Right!=nil{ prenext=prenext.Right } prenext.Right=cur.Right cur.Right=next cur.Left=nil } cur = cur.Right } } 八股：redis的使用场景 redis的压缩链表讲一下 为什么有key value来记录，后面问的啥没听明白？\n评价为有点像KPI面，中途还一直东张西望，皱眉头，我跟他讲项目讲了一下就被打断了，直接开始帮我总结项目，结果总结的还是错的难绷，感觉有点不当人啊哈哈哈\n秋招 Boss 投 具身智能 （转去官网投了） 最右（转去官网投了） 乐牛（转去官网投了）约一面了 三面后oc 希望学 笔试 十号下午三点一面 没消息 金山办公软件（转去官网投了）三个志愿全挂 得到 转去官网了 光智时光 （停止招聘了） 小黑盒，说hc太少11月再说 人人租 线下面不去 肯爪 未读重发 北京人工智能 学历不够 心潮无限 已投 潞程科技（停止招聘了） 佳期投资（停止招聘了） 小马智行（还在评估） 梦马智能 （投了） 拉魔兰 （没看） 华润数科（没看） 长亮科技 （没看） 货拉拉 （投了） 方宇智云（没看） 爱奇迹 （投了） 叠腾科技（没看） 阿博次（没看） 终极幻境（没看） 贝乐虎（看了） 小天才（投了） 牛客投 途游（转去官网了） 迅雷(25号笔试时间冲了) 海能达 简历过 米可世界 官网投 陌陌 约一面了 拼多多(22号笔试)笔试完挂 深信服 9.10 晚七点笔试（开会没去等下次） 挂了转岗 信也科技 中国电信（09月28日 09:00-10:30笔试） 小红书 腾讯云智 龙湖集团 滴滴 9.13晚七点笔试（13号不行） FunPlus 9.13 晚七点笔试（13号不行）9.21笔试，笔试完挂 米哈游 笔试 挂了 贝壳找房（一开始投的大模型，后面投go去了）也没消息 B站 百度笔试没空，估计没下一波了 得物 作业帮（北京简历挂）重投武汉了（还是挂） 商汤 超参数 25号晚七点一面(部门方向不对，写C++的，答得还行结果挂了) 奇安信 小米 测评 笔试19，30号下午四点一面（面完了感觉不太行，云原生这块感觉一般。。。）挂了应该 4399 简历过 18日晚七点笔试 三面完 虾皮(24号早笔试）一面了 科大讯飞 测评 简历挂 360 14号笔试 旷视 游卡 字节 flow直接挂，被捞去AI工程师了难蚌啊（拒了直接） 腾讯 momenta 简历挂 快手 简历挂 联通数科 美图 同程（估计应该也没了，岗位都搜不到了） 星辉游戏 美的 锐捷（简历挂） 微派 阶跃星辰 （简历挂） 京东（测评） 三七互娱 叠纸游戏（挂了） minimax（简历挂） 沐瞳科技 合合信息 腾讯音乐 麦吉太文 收钱吧（人才库） 游酷盛世 万兴科技 好未来 笔试，约面了结果邮件没收到。。。 中企云链 联通数科 百融云创 联想 微策略 影石 童心制物 简历挂 内推投 元象科技 一直挂着不给面。。 安可创新（笔试） 阿里国际 道旅科技\n9.9开投 9.22截止目前投递60家，简历挂4家 笔试测评11家 约面2家 目标3-5个offer 10.28截止目前投递90家，简历挂13家，笔试二十多家了，目前约面6家，目标一个offer就行（绷）\n11.17目前状态：\n最右 申请成功 具身智能 申请成功 乐牛 oc 金山三个志愿全挂 希望学 一面完一个月没动静，不管了 得到 评估中 途游 简历挂 米可世界 后端简历挂 golang游戏开发评估中 小天才 查不到投递记录 陌陌 一面后无消息 信也科技 简历筛选 中国电信 查都不知道怎么查。。 小红书 初筛 腾讯云智 初筛 龙湖集团 初筛 滴滴 笔试考察状态 贝壳找房 初筛 B站 初筛 百度 笔试阶段 得物 简历挂 商汤 二志愿挂 一志愿还没评估 奇安信 初筛 小米 一面挂 4399 三面完评估 虾皮 二面完 360 初筛 旷视 初筛 游卡 初筛 字节 投实习简历评估 腾讯 还没被捞过 更新一下简历吧 美图 初筛 美的 初筛 京东 筛选 刷新一下简历吧 三七互娱 初筛 沐瞳科技 初筛 万兴科技 简历挂 联想 已投递 影石 已投递 元象科技 专业面-未处理 安可创新 挂了 阿里国际 评估都没评估\n超参数秋招一面（）\n项目讲一下，说先讲七牛的，我说七牛不太行，然后就说讲小鹅通的了\n讲一下项目架构\n项目：接口并发量怎么样\n事务ACID\n上线前有做压测吗\n如果tcp挥手出现大量time_wait怎么办 服务器端口可使用量不够了 端口复用： 在某些操作系统中，当一个应用程序监听一个端口时，其他应用程序也可以监听同一个端口，只要它们使用的是相同的本地地址和端口号。操作系统会根据连接请求的远程地址和端口来决定将请求发送给哪个应用程序。\n数据库B+树为什么叶子节点不存放数据，性能就比B树快\n一次性查的时候加载到内存的数据会比较多\n如果cpu过高，并发量过大怎么排查 进服务器里面用top命令看一下 1、top命令查看任务管理器 2、ps H -eo pid,tid,%cpu | grep 16470(进程) 3、printf “%x\\n” 线程 转成十六进制 4、jstack 5、东西太多 使用 jstack 进程 | grep 406d 查看具体位置，这样就定位到了具体的代码。\n如果接口延时过高怎么办，调下游接口时延时过高 1.sql响应比较慢？慢查询，索引失效？ 2.Explain（type，key，key_len）类型，用到的索引，索引实际长度 3.并发调多个接口 4.缓存直接查redis 5.批量查数据库 6.记录日志，落库等操作采用异步处理 7.避免大事务（接口超时） 8.调接口，超时策略，重试策略，改成异步mq 9.分页处理，传输数据量过大 10.分库分表\ntcp，udp区别\nhttp，tcp区别与联系\n说要问C++八股，我说没怎么看。。。\n有性能优化的经验吗，讲一个例子 sql较长，加索引\n算法：左上角到右下角最小路径和，动态规划秒了\n反问： 部门：工程部门 业务：从算法到落地 接口并发量比较高，说这边接口都是毫秒级别返回的\n半个小时后，挂\u0026hellip;.\n小米云原生（30分钟）： 面试官还以为我是实习，绷不住了哈哈哈\nDocker 容器怎么生成的，内部是怎么样的讲一下\nk8s架构\n切片的底层 type slice struct { // 指向起点的地址 array unsafe.Pointer // 切片长度 len int // 切片容量 cap int } 切片并发安全吗？ 不安全\n切片的扩容机制 下面我们捋一下切片扩容的流程. 当 slice 当前的长度 len 与容量 cap 相等时，下一次 append 操作就会引发一次切片扩容. 切片的扩容流程源码位于 runtime/slice.go 文件的 growslice 方法当中，其中核心步骤如下： • 倘若扩容后预期的新容量小于原切片的容量，则 panic • 倘若切片元素大小为 0（元素类型为 struct{}），则直接复用一个全局的 zerobase 实例，直接返回 • 倘若预期的新容量超过老容量的两倍，则直接采用预期的新容量 • 倘若老容量小于 256，则直接采用老容量的2倍作为新容量 • 倘若老容量已经大于等于 256，则在老容量的基础上扩容 1/4 的比例并且累加上 192 的数值，持续这样处理，直到得到的新容量已经大于等于预期的新容量为止 • 结合 mallocgc 流程中，对内存分配单元 mspan 的等级制度，推算得到实际需要申请的内存空间大小 • 调用 mallocgc，对新切片进行内存初始化 • 调用 memmove 方法，将老切片中的内容拷贝到新切片中 • 返回扩容后的新切片 函数传切片带指针和不带指针有什么区别 一样的，底层都是传递指针，函数里修改了切片的值，函数外都会改边，只是说传了指针的话还可以改一下切片的长度和容量\n循环中修改切片内容，切片实际上会改变吗 包会的，面试官还说不会。。。。 [图片]\nmap中key的类型有什么限制吗 在Go语言中，map 的键（key）类型有一些限制，这些限制确保了键的唯一性和可比较性。以下是 map 键类型的限制：\n必须是可比较的：键类型必须支持比较操作符，即它们必须是可比较的。这意味着它们必须能够进行相等性和不等性比较。 必须是基础类型或定义了比较方法的类型：Go语言中的基本数据类型（如整数、浮点数、字符串、布尔值）都是可比较的，因此它们可以作为 map 的键。此外，如果一个自定义类型定义了比较方法（即实现了 Comparable 接口），它也可以作为 map 的键。 不能是切片、映射、函数或通道：这些类型是不可比较的，因为它们是引用类型，它们的比较依赖于它们的指针地址，而不是它们的值。 不能是指针：尽管指针是可比较的，但它们通常不作为 map 的键，因为指针的值（即它们的地址）可能会变化，这可能会导致 map 的行为不稳定。 不能是接口类型：接口类型本身是可比较的，但它们不能保证存储的值是可比较的，因此不能直接用作 map 的键。 以下是一些可以作为 map 键的类型的例子： 整数类型（如 int, int32, int64） 浮点数类型（如 float32, float64） 布尔类型（bool） 字符串类型（string） 结构体（如果实现了 Comparable 接口） 数组（如果它们是固定长度的，并且数组的元素类型是可比较的） 为什么key必须是可比较的 在Go语言中，map 的键必须是可比较的，这是因为 map 的内部实现和工作原理所决定的。以下是为什么 map 的键必须是可比较的几个关键原因：\n快速查找：map 提供了快速查找功能，它通过哈希函数将键映射到一个桶（bucket）中。为了快速确定元素是否存在于 map 中，以及元素的存储位置，map 需要能够比较键值。\n避免冲突：当两个键通过哈希函数映射到同一个桶时，会发生哈希冲突。为了解决冲突，map 实现了一个链表或其他数据结构来存储具有相同哈希值的键。在这种情况下，map 需要能够比较键以确定它们是否相等。\n唯一性：map 要求每个键都是唯一的。如果两个键被认为是相等的，那么它们将被认为是同一个键。因此，map 需要能够比较键以确保它们的唯一性。\n内部数据结构：map 的内部数据结构依赖于键的可比较性。例如，map 可能会使用红黑树来解决哈希冲突，这需要键能够被比较以维护树的有序性。\n语言设计：Go语言的设计哲学强调简洁和效率。要求键是可比较的，简化了 map 的实现，使得 map 能够提供快速的查找、插入和删除操作。\n避免歧义：如果键不可比较，那么在尝试添加一个新键时，map 将无法确定新键是否已经存在，这会导致操作的不确定性和潜在的错误。\n接口一致性：要求键是可比较的，确保了所有 map 的键都遵循相同的规则，这有助于保持语言的一致性和可预测性。\n希望学秋招一面（30min）\nmysql有哪些索引，使用场景有哪些\n索引失效场景\n慢sql 查询\n四种隔离级别\nmysql怎么解决幻读 mvcc+间隙锁 b+树和b树的区别\nb+树介绍一下\ngo有哪些引用和非引用的变量类型 引用类型：“ 引用类型的变量存储的是数据的引用（地址），而不是数据本身。对引用类型变量的修改会影响所有引用同一个地址的变量。Go中的引用类型包括：\n切片（Slice）：对数组的抽象，提供动态数组的功能。 映射（Map）：存储键值对，通过键来索引。 通道（Channel）：用于在Go协程之间同步和传递数据。 接口（Interface）：存储值的类型和值本身，可以是任何类型的值。 函数：在Go中，函数也是引用类型。 非引用类型（值类型） 非引用类型的变量直接存储数据的副本。对非引用类型变量的修改不会影响到其他变量。Go中的非引用类型包括： 布尔型（bool）：表示逻辑值true或false。 数值型： 整数类型：int、int8、int16、int32、int64、uint、uint8、uint16、uint32、uint64、uintptr。 浮点数类型：float32、float64。 复数类型：complex64、complex128。 字符串（string）：不可变的字符序列。 结构体（Struct）：可以包含零个或多个不同类型的字段。 go的channel讲一下无缓冲和有缓冲的场景\n无缓冲通道（Unbuffered Channel） 无缓冲通道在发送（send）和接收（receive）操作之间建立了一个直接的同步机制。发送操作会阻塞，直到另一个goroutine执行接收操作，并且接收操作也会阻塞，直到有数据可读。这种机制确保了发送的每项数据都有一个对应的接收操作。 读写场景：\n发送数据： 当你尝试向一个无缓冲通道发送数据时，如果通道中没有空间（因为没有被其他goroutine接收数据），发送操作会阻塞，直到另一个goroutine从通道中接收数据。 接收数据： 类似地，如果你尝试从一个无缓冲通道接收数据，而通道中没有数据（因为没有其他goroutine发送数据），接收操作会阻塞，直到数据被发送到通道。 无缓冲通道通常用于需要确保发送和接收操作严格同步的场景，例如在生产者-消费者模型中，生产者生产一个项目后，消费者立即处理它。 有缓冲通道（Buffered Channel） 有缓冲通道在通道中维护了一个固定大小的缓冲区，允许发送操作在缓冲区未满时不必等待接收操作即可进行。只有当缓冲区满时，发送操作才会阻塞。同样，接收操作只有在缓冲区为空时才会阻塞。 读写场景： 发送数据： 向有缓冲通道发送数据时，如果缓冲区未满，数据会被存储在缓冲区中，发送操作不会阻塞。 如果缓冲区已满，发送操作会阻塞，直到缓冲区中有足够的空间（即其他goroutine从通道中接收数据）。 接收数据： 从有缓冲通道接收数据时，如果缓冲区不为空，可以直接从缓冲区中读取数据，而不需要等待发送操作。 如果缓冲区为空，接收操作会阻塞，直到有数据被发送到通道。 有缓冲通道适用于可以异步处理数据的场景，其中发送者不必等待接收者处理每一项数据。这可以提高性能，因为发送者不必为每一项数据的接收而阻塞。 小鹅通项目架构介绍一下\n怎么获取模型\n流式响应讲一下\n美团ai一面\nhttp的keep-alive是啥\nhttp的长连接，只要任意一段没有明确提出断开连接，则保持tcp连接状态，这样客户端发送另一个请求的时候会使用同一个连接，可以减少tcp连接资源的消耗\n什么时ddos攻击\nDatabase link 的使用场景是啥\n设计一个抢票场景题，考虑到高性能和公平性\ngo的time包怎么用的\n乐牛一面（文俊leader面的，蚌）\nlinux常用命令\nflink，高并发架构\n学习数据上报架构 多个pod 每个pod多协程将学习数据推到kafka不同分区 kafka再将数据放到 pg,mysql\nnginx负载均衡\n复杂接口，实习难点\nai客服场景题\n开发流程\n挚文集团一面\n关闭已关闭的channel会怎么样，为什么会panic 尝试关闭一个已经关闭的channel也会导致panic，因为channel只能被关闭一次，再次关闭没有意义，Go语言的运行时会通过panic来阻止这种非法操作 Def func的顺序 如果有多个defer语句，那么它们的执行顺序是后进先出（LIFO），即最后被defer的函数会第一个被执行。\n先def还是先return defer语句会在函数返回之前执行\n协程之间怎么通信？除了channel还有其他方法吗 协程（goroutine）之间的通信通常是通过channel来实现的\nContext：context.Context接口经常用于控制goroutine的生命周期。它可以传递取消信号或超时限制给一组goroutine，使它们能够在特定条件下优雅地停止执行\nmap并发有问题怎么解决？ 在Go语言中，当多个goroutine并发访问同一个map时，会存在并发安全问题。Go的内建map类型并不是并发安全的，这意味着在多个goroutine中并发读写同一个map可能会导致数据竞争和不一致性问题。 为了解决这个问题，可以使用以下几种方法：\n使用sync.Map：从Go 1.9开始，标准库提供了sync.Map类型，它是为了并发场景设计的，并发安全的map。sync.Map通过减少锁的使用，提高了并发性能。它提供了Store、Load、Delete等方法来操作map，并且还有一个Range方法用于遍历map中的所有键值对。使用sync.Map可以避免在并发访问时发生panic，并提高程序的并发性能。 手动加锁：可以通过在每个goroutine中对map的操作加上互斥锁（sync.Mutex或sync.RWMutex）来保证并发安全。这种方法简单直观，但可能会因为锁的竞争而影响性能。 分片加锁：这是一种更细粒度的锁机制，将map分割成多个片段，每个片段由一个锁保护。这样，不同的goroutine可以同时操作不同的片段，从而减少锁竞争，提高并发性能。这种方法的实现相对复杂，但可以提供更好的性能。 使用第三方库：有一些第三方库提供了并发安全的map实现，例如orcaman/concurrent-map。这些库通常也采用分片加锁的策略来提高并发性能。 内存泄漏怎么排查ggprof有用过吗 https://blog.csdn.net/weixin_45565886/article/details/137158092?ops_request_misc=\u0026request_id=\u0026biz_id=102\u0026utm_term=golang%E5%86%85%E5%AD%98%E6%8E%92%E6%9F%A5\u0026utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-137158092.142^v100^pc_search_result_base8\u0026spm=1018.2226.3001.4187\n程序都有添加pprof监控，于是直接通过go tool pprof分析\n获取堆内存分配情况:go tool pprof http://xx/debug/pprof/heap\n过滤出占用堆内存前10的方法：top 10\ntop 10\nflat：表示此函数分配、并由该函数持有的内存空间。 cum：表示由这个函数或它调用堆栈下面的函数分配的内存总量。 查看方法详情：list testReadAll\n最后定位到ioutil.ReadAll这个方法占用了太多内存。 因为我们的客户有几百M的图片，所以一旦并发以上来很可能打爆。因此这里需要改成流式的io.Copy。\n定位到问题后，直接使用io.copy()改用流式方式给前端返回。\nioutil.ReadAll：会将数据一次性加载到内存。 io.Copy：流式拷贝，不会导致内存暴涨 因此对于大文件或者数据量不确定的场景推荐使用io.Copy\n查看堆内存信息 go tool pprof http://IP:Port/debug/pprof/heap\n查看cpu信息 go tool pprof http://IP:Port/debug/pprof/profile\n-seconds=5设置采样时间为5s go tool pprof -seconds=5 http://IP:Port/debug/pprof/profile\n查看协程信息 go tool pprof http://IP:Port/debug/pprof/goroutine\n查看代码阻塞信息 go tool pprof http://IP:Port/debug/pprof/block\nflat：当前函数分配的内存，不包含它调用其他函数造成的内存分配 flat%：当前函数分配内存占比 sum%：自己和前面所有的flat%累积值 cum：当前函数及当前函数调用其他函数的分配内存的汇总 cum%：这个函数分配的内存，以及它调用其他函数分配的内存之和\n进程，线程，协程区别\n代码中有没有做过监控\n项目的代码目录写来看一下\n实习中有没有什么难点\n如果内存飙高怎么做，top命令里面看的是什么 top 命令可以实时显示正在执行进程的 CPU 使用率、内存使用率以及系统负载等信息。其中上半部分显示的是系统的统计信息，下半部分显示的是进程的使用率统计信息。\n除了简单的 top 之外，我们还可以通过 top -Hp pid 查看具体线程使用系统资源情况：\nhttps://blog.csdn.net/jiankunking/article/details/135091771?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522A04EE8FD-E5F5-44FC-834E-6C4CA9F413E6%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D\u0026request_id=A04EE8FD-E5F5-44FC-834E-6C4CA9F413E6\u0026biz_id=0\u0026utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-135091771-null-null.142^v100^pc_search_result_base8\u0026utm_term=golang%E7%BA%BF%E4%B8%8A%E5%86%85%E5%AD%98%E9%A3%99%E9%AB%98\u0026spm=1018.2226.3001.4187\n还有什么linux命令经常用\nTcp udp区别\ngin框架中的中间件一般写了什么 网关透传的用户信息：app_id,_user_id Http https\n502 504错误码\n分布式锁有用过吗，说个场景\n499错误码什么意思？ 在Nginx中，499状态码表示客户端在服务器处理请求过程中主动关闭了连接\n算法 双指针easy 题\n职业规划\n业务：私有云\n虾皮秋招一面（五十分钟）\n面试官对我的项目不太懂，跟他讲了好久\n为什么不直接调大模型 因为不准啊。。。 一上来就问qps多少，红了\n高并发情况下请求打过来外部怎么弄\n内部服务进行channel+协程池并发处理请求？ 采用分布式，在网关层使用类似于Nginx的工作作为高性能的Web服务器和反向代理，实现负载均衡。 做异步削峰，把请求放到消息队列中进行异步处理。\n内部存储和协程不考虑\n网关负载均衡？\n负载均衡算法有啥 轮询 ip哈希 url哈希 最短响应时间 加权轮询\n索引一般怎么建 字段唯一性 经常用where查询的字段 经常用group by 和order by的字段\n为什么读多才建立，写多不建吗？\n写入性能影响： 写多：每次对数据库进行插入（INSERT）、更新（UPDATE）或删除（DELETE）操作时，不仅需要修改表中的数据，还需要更新索引。这会增加额外的写操作，可能会降低写入性能，尤其是在写入操作非常频繁的情况下。 索引维护开销： 更新索引需要额外的磁盘I/O和CPU资源，这可能会导致写入操作变慢，尤其是在有大量索引的情况下。 索引空间占用： 索引本身也需要占用存储空间，对于写多的场景，如果数据经常变化，索引可能会频繁更新，这会导致索引本身的维护成本增加。 索引选择性： 在写多的场景下，如果索引的选择性不高（即索引列中重复值很多），那么索引的效果会大打折扣，因为数据库仍然需要扫描大量的索引条目来找到对应的数据。 要查询手机号的话要不要建立索引 可以吧\n事务acid\n隔离级别\n可重复读和读提交的区别\n不可重复读的情况给一个场景 库存扣减 扣库存+可重复读的场景怎么办，如果都只能看到自己的事务的时候，那这样不会超扣吗\n我说使用成消息队列改串行化或者加锁，他说这样打过来一万个请求需要排队买，会特别慢，我说不会了哈哈哈\n感觉可以用乐观锁，扣完再看有没有超扣，有的话回滚\nhttp和tcp的区别\nhttp和tcp中间还有哪几层\nhttp每次连接都需要tcp三次握手吗\n算法：最佳股票买卖，a了\n4399ai中台一面（秋招以来十多场面试中最搞的一集😂40min）\n面试官一上来直接表明他们也做的数字人+rag，让你介绍一下，说你们的肯定比我们领先 我说我们刚起步很水哈哈哈😂\nrag中指代情况怎么解决 就提的问题中不带（你，我）等人称的情况，怎么让ai知道是跟谁说话，不了解一些特定名词怎么办 我说用提示词去做问题优化，不满意\nrag中知识库的分段是怎么分的，按照不同的文本长度分有什么区别 我说就一个文档一个分段，为了保证准确率，他说一个分段字太多了不好，对客户的知识库上传也不友好，我说是我太菜了，还不了解\n一个知识点在不同的上传文件里，怎么合到一个分段 不太会，向量聚合？\n有调研过哪些开源的rag ？ 我说了dify，maxkb，graphrag，memorag还有几个。。其实后面的都没看过，随便说的\n你们做的数字人业务讲一下（还没太接触，随便编一下）\n数字人当中如果大模型返回的文本过长，那ai要一直讲很久，别人会不耐烦，怎么优化\n这个也不会，已经麻了，后面想起来了是流式打断？但其实我也没了解过，讲不明白\n又闲聊了一下我做的rag，说我做的没法商用，只能回答qa，多丢几篇文档进去就不行了（我怎么感觉还挺准的，反正先认可他吧，说他们厉害）\n看我答不上来，开始问八股。。\ngo的中间件怎么实现 答了gin框架的中间件\ngorm中mysql表里没有设外键，但是逻辑上还是有外键，怎么实现， 语速太快没听清到底要不要设外键，答了个钩子函数\nkafka生产者消费者的关系 讲了partition分区，发布订阅，顺序性之类的八股 还有实习的使用场景\nkafka中怎么做消息确认 说了三种级别的ack确认机制\nes拿来做了什么 讲了两段实习的使用场景\n为什么用es做向量数据库不用pg 我讲了一下三种数据库的对比，最后用的就是pg😂\n前端熟不熟悉，我说会一些\nvue主组件和副组件的关系 不会，父子关系？\nvue的数据管理 不会，好久没看过vue了真不会\n讲一下你对vue的理解吧（看我都答不上来了笑死） 讲了一下路由，组件化，响应式之类的，其实也不是完全都学过\n反问问面试官上面问的那些怎么做优化的，他说有技术壁垒不能告诉你，可以讲一个问题优化，可以给一些优化的样例放到提示词里，要用最好的模型，但又要考虑成本，又说不要用提示词？我也有点没听懂，感觉也不是很厉害啊。。。\n问了下兴趣爱好，主动评价说我基础还可以，但有些细节没了解到。\n听同学说是天坑公司，点击就送的，但怎么感觉难度还挺大。。。 而且他语速巨快，耳机还差，听的我难受的一匹，大概率挂\n虾皮二面\n一上来先问项目\nrag怎么把百分之70提升到百分之90的\n讲了rag的几个链路\n问题优化怎么做的\n如何减少token\n怎么检索的\nes的倒排索引\n小鹅通这边做了啥，业务是啥\n写的业务逻辑\n讲到了统一商品\n数据一致性 开始了，调电商接口，调完之后回调了之后我们去创建对应的机器人配置,这种创建订单和创建机器人如何保证数据一致性呢\n如果接口响应慢呢怎么解决\n重试几次？超时时间有做吗？具体接口响应时间是多少？\n如果直接没有响应就直接算失败吗，怎么办。\n如果你这边算失败，但是他们那边过了一会儿之后下单成功了，那我怎么整\n你讲到了分布式事务，这个可以后面再讲\n现在我不用分布式事务，怎么解决这个问题呢？\n我说用本地消息表，把每次请求记录下来，然后定时看一下哪些是没有收到回调的，去手动把他创建一下\n他说不需要用人工，想要在系统上面做\n然后我就讲了定时任务扫描呗，他就没继续聊了\n接下来让我介绍分布式事务，讲讲我的理解\ncap理论了解吗，讲一下\n接下来是八股轰炸时间\n乐观锁 悲观锁\n在mysql里面怎么实现 乐观锁 悲观锁的\n死锁产生的条件\nredis中zset的底层结构\n讲一下跳表的查询过程\n跳表查询复杂度是多少\nredis的持久化rdb aof\naof的重传（不会）\n反问：数字银行，线上app，微众银行，java技术栈为主。。。\n腾讯（csig腾讯健康一面1h40min）\n首先拷打golang协程，gmp调度\nGmp中的全局队列和私有队列：为什么要有全局队列，队列里放的是什么，一个协程吗？ 1.全局队列的作用：\n全局队列（Global Queue）是一个所有可运行的goroutine共享的队列。它用于存放那些无法立即在本地队列中找到执行机会的goroutine。当一个新的goroutine被创建时，它首先会被放入当前P（Processor）的本地队列。如果本地队列已满，这个goroutine就会被放入全局队列。 全局队列的设计旨在提高goroutine的调度效率，减少上下文切换的开销，并确保所有处理器（P）都能够访问到待执行的goroutine，从而提高了goroutine的调度灵活性。 2.队列里放的是什么： 全局队列和私有队列中存放的是等待运行的goroutine（G）。goroutine是Go语言中的轻量级线程，它们是参与调度与执行的最小单位。 3.为什么要有全局队列： 全局队列的存在使得当某个处理器的本地队列空了时，可以从全局队列中获取一批goroutine放到本地队列中，这样可以保证线程（M）始终有任务执行，提高了线程的利用率和系统的并发性能。 全局队列还有助于实现负载均衡和工作窃取（work stealing）机制。当一个线程没有可执行的goroutine时，它可以从全局队列或其他P的本地队列中偷取goroutine来执行。 4.私有队列： 每个P都有自己的本地队列，用于存放待执行的goroutine。新建的goroutine会优先放入本地队列，如果本地队列满了，则会将一部分goroutine移动到全局队列。 什么时候会放到全局队列内 本地队列满了的时候\n如果多个线程中，每个线程中协程内部所消耗的内存花费的时间不一样，消耗内存不均衡，那应该怎么办呢 抢占调度？： 倘若 g 执行系统调用超过指定的时长，且全局的 p 资源比较紧缺，此时将 p 和 g 解绑，抢占出来用于其他 g 的调度. 等 g 完成系统调用后，会重新进入可执行队列中等待被调度. 值得一提的是，前 3 种调度方式都由 m 下的 g0 完成，唯独抢占调度不同. 因为发起系统调用时需要打破用户态的边界进入内核态，此时 m 也会因系统调用而陷入僵直，无法主动完成抢占调度的行为. 因此，在 Golang 进程会有一个全局监控协程 monitor g 的存在，这个 g 会越过 p 直接与一个 m 进行绑定，不断轮询对所有 p 的执行状况进行监控. 倘若发现满足抢占调度的条件，则会从第三方的角度出手干预，主动发起该动作.\n还有一种就是p的本地队列的goroutine已经执行完了，他就会去全局队列里拿一半过来，这一定程度上也可以起到负载均衡的效果\n如果调一个服务一直没响应怎么办\n网络问题排查 1.1 检查网络延迟 工具：使用 ping 或 traceroute 命令检查与微服务之间的网络连接。 步骤： 使用 ping 命令测试关键服务之间的响应时间。 使用 traceroute 命令追踪数据包到达目标服务的路径，检查是否有延迟或丢包现象。 1.2 检查服务间通信 工具：使用 telnet 或 curl 命令测试服务间通信。 步骤： 测试关键服务的端点是否可访问。 检查是否有防火墙或网络策略阻止服务间通信。\n2.资源瓶颈排查 2.1 检查CPU使用率 工具：使用 top 或 htop 命令查看CPU使用情况。 步骤： 查看CPU使用率是否接近100%，这可能表明CPU资源不足。 分析进程使用情况，找出占用CPU资源最多的进程。 2.2 检查内存使用情况 工具：使用 free 或 vmstat 命令查看内存使用情况。 步骤： 查看内存使用率是否接近100%，这可能表明内存资源不足。 分析内存使用情况，找出占用内存最多的进程或服务。\n3.慢sql\n4.服务内部代码死锁了\n啥是死锁： 在 Go 语言中，死锁通常发生在两个或多个 goroutine 互相等待对方释放锁，而没有一个能够继续执行的情况。这通常涉及到锁的使用不当，例如：\n锁的顺序不一致：当多个 goroutine 尝试以不同的顺序获取多个锁时，可能会导致死锁。 锁的嵌套使用：在持有一个锁的同时尝试获取另一个锁，尤其是在不同的 goroutine 中，可能会导致死锁。 锁的超时：如果一个 goroutine 在等待另一个 goroutine 释放锁时超时，而后者也在等待前者，就可能发生死锁。 锁的遗漏释放：在某些情况下，如果锁没有被正确释放，也可能导致死锁。 例子： package main import ( \u0026ldquo;fmt\u0026rdquo; \u0026ldquo;time\u0026rdquo; )\nfunc main() { var lock1, lock2 sync.Mutex\ngo func() { lock1.Lock() time.Sleep(1 * time.Second) // 模拟耗时操作 lock2.Lock() fmt.Println(\u0026quot;Locked both\u0026quot;) lock2.Unlock() lock1.Unlock() }() go func() { lock2.Lock() time.Sleep(1 * time.Second) // 模拟耗时操作 lock1.Lock() fmt.Println(\u0026quot;Locked both\u0026quot;) lock1.Unlock() lock2.Unlock() }() time.Sleep(10 * time.Second) // 给足够的时间让 goroutine 运行 }\n死锁了怎么排查（https://blog.csdn.net/u013536232/article/details/107868474） 使用gopprof打开浏览器，输入http://localhost:7890/debug/pprof/，选择goroutine，即可获取程序中每个goroutine的调用信息 （内部实现：在runtime包的内部实现中，pprof使用runtime_goroutineProfileWithLabels函数来获取goroutine的堆栈信息。这个函数会遍历所有的goroutine，并收集它们的堆栈信息以及标签（如果有的话）。）\n查找每个goroutine的堆栈调用信息，看有些goroutine他卡在哪一步了\n死锁怎么找到死锁对应的代码呢 一般卡住的goroutine会有”sync.runtime_SemacquireMutex“这种字段，并且会有对应的代码片段\n内存飙高怎么排查 top命令查看进程，pprof获取程序内部的内存快照\nggprof底层是怎么做到找到内存最高的几行命令的 pprof工具获取堆内存分配情况的底层实现主要依赖于Go语言的runtime包，具体来说，是通过runtime/debug包中的WriteHeapDump函数实现的。以下是详细的实现机制：\nruntime/debug.WriteHeapDump函数： WriteHeapDump函数会将当前堆内存中所有对象的描述写入到一个文件描述符中。这个函数在执行时会暂停所有goroutine的执行，直到堆转储完全写入，以确保在快照过程中不会有内存分配或修改发生。\n暂停Goroutine： 在生成内存快照时，所有的goroutine都会被暂停，这是为了防止在快照过程中进行内存分配或修改。这个暂停操作确保了内存快照的一致性和准确性。\n堆内存快照： 快照会记录堆内存中所有对象的分配情况，包括对象的类型、大小、引用关系等。这些信息对于分析内存泄漏和性能瓶颈至关重要。\n栈内存和Goroutine快照： 除了堆内存，快照还会记录所有goroutine的栈内存信息和goroutine的状态信息，包括栈帧内容、调用关系等。\n浏览器输入url解析的流程 解析url 缓存判断 dns解析 获取mac地址 建立tcp连接或者将请求打包成一个包经过路由层转发到目标服务器 服务器处理请求并且返回响应 客户端接收到请求后解析并展现在前端\n中间说到的路由转发是哪块的路由，ip层的？ 网络层（IP层）进行的 路由怎么实现转发的，转发的过程有了解过吗\n查找路由表：路由器接收到一个数据包后，会查找其路由表，确定下一跳的IP地址。 封装数据包：路由器将数据包封装在一个新的帧中，并在帧中指定下一跳的MAC地址。 发送数据包：路由器通过物理网络（如以太网）将封装好的数据包发送给下一跳。 服务端收到包之后是怎么解析传过来的包的，怎么转成http报文\nTCP层到应用层的转换： 服务端接收到TCP数据后，首先会检查TCP头部，确认数据包的完整性和顺序，并进行必要的TCP层处理，如确认应答、窗口滑动等。 HTTP报文的解析： 一旦TCP连接建立并且数据包被确认无误，数据将被传递到应用层，即HTTP服务器。HTTP服务器会解析这些数据，将其从TCP数据流中分离出来。 HTTP请求报文由三部分组成：请求行、请求头和请求体。 请求行：包含请求方法（如GET、POST）、请求的资源路径和HTTP协议版本。 请求头：包含一系列键值对，提供客户端环境、请求体信息等附加信息。 请求体：对于POST或PUT请求，请求体会包含发送给服务器的数据。 解析HTTP请求行： 服务端会首先解析请求行，获取请求方法、URI和HTTP版本号。 解析HTTP请求头： 接着，服务端会解析请求头，这些头部字段包含了客户端环境信息、请求体的类型和大小等重要信息。 解析请求体： 如果请求包含请求体（如POST请求），服务端会进一步解析请求体中的数据。 写个伪代码吧 package main\nimport ( \u0026ldquo;bufio\u0026rdquo; \u0026ldquo;bytes\u0026rdquo; \u0026ldquo;fmt\u0026rdquo; \u0026ldquo;io\u0026rdquo; \u0026ldquo;net\u0026rdquo; \u0026ldquo;strings\u0026rdquo; )\n// 解析HTTP请求报文的函数 func parseHTTPRequest(conn net.Conn) { defer conn.Close()\n// 使用bufio.Reader来简化读取操作 reader := bufio.NewReader(conn) // 读取请求行（请求方法、URI、HTTP版本） requestLine, err := reader.ReadString('\\n') if err != nil { fmt.Println(\u0026quot;Error reading request line:\u0026quot;, err) return } fmt.Println(\u0026quot;Request Line:\u0026quot;, requestLine) // 解析请求行 parts := strings.Split(requestLine, \u0026quot; \u0026quot;) if len(parts) != 3 { fmt.Println(\u0026quot;Invalid request line\u0026quot;) return } method, url, httpVersion := parts[0], parts[1], parts[2] fmt.Println(\u0026quot;Method:\u0026quot;, method) fmt.Println(\u0026quot;URL:\u0026quot;, url) fmt.Println(\u0026quot;HTTP Version:\u0026quot;, httpVersion) // 读取请求头 var headers map[string]string for { line, err := reader.ReadString('\\n') if err != nil { fmt.Println(\u0026quot;Error reading headers:\u0026quot;, err) return } if line == \u0026quot;\\r\\n\u0026quot; { // 空行表示请求头结束 break } headerParts := strings.SplitN(line, \u0026quot;:\u0026quot;, 2) if len(headerParts) != 2 { fmt.Println(\u0026quot;Invalid header line\u0026quot;) continue } headerName := strings.TrimSpace(headerParts[0]) headerValue := strings.TrimSpace(headerParts[1]) headers[headerName] = headerValue fmt.Println(headerName, \u0026quot;:\u0026quot;, headerValue) } // 读取请求体（如果存在） contentLength, exists := headers[\u0026quot;Content-Length\u0026quot;] if exists { contentLengthInt, err := strconv.Atoi(contentLength) if err != nil { fmt.Println(\u0026quot;Error parsing Content-Length:\u0026quot;, err) return } body, err := reader.Read(make([]byte, contentLengthInt)) if err != nil { fmt.Println(\u0026quot;Error reading body:\u0026quot;, err) return } fmt.Println(\u0026quot;Body:\u0026quot;, string(body)) } }\nfunc main() { // 假设我们已经有了一个TCP连接 listener, err := net.Listen(\u0026ldquo;tcp\u0026rdquo;, \u0026ldquo;:8080\u0026rdquo;) if err != nil { fmt.Println(\u0026ldquo;Error listening:\u0026rdquo;, err) return } defer listener.Close()\nfor { conn, err := listener.Accept() if err != nil { fmt.Println(\u0026quot;Error accepting:\u0026quot;, err) continue } go parseHTTPRequest(conn) } } http有哪些内容 [图片] 获取http报文是按照什么分割的？\n获取一个连接，怎么分割的http报文？\n报头和报文中间是怎么分割的？\n（中间还有一大串解析的内容，直接懵逼）\ntcp粘包怎么解决？\n那tcp是按照标志位和固定长度去做切分的，那http呢？\nHttp 302 304 ，502 504错误码区别\n算法题：100万亿32位int整型找一个中位数\nint32位整数不行，一直往下衍生到0和1；0和1和2；最后让我写个0-32的，这个写出来了，贼难蚌。\ntme酷狗后端校招一面（kpi）\nbase广州，安全部门\n对项目完全不感兴趣，感觉被kpi\n十亿个数，怎么找到最大 一百个数 维护一个最小堆，每次那一部分数出来进行排序，排序的时候如果有比堆顶高的数，就把这个数放到堆顶。\n双向链表查询复杂度 on 有什么办法可以把他变成近似于二分查找的O(logn)复杂的 跳表\n跳表的怎么查找的\n从顶层开始查找：查找操作从跳表的最高层开始，即最顶层的链表。这一层的节点数量较少，因此可以快速地跳过大量元素。\n向右移动：在当前层，从头节点开始向右移动，直到遇到一个节点，其值大于或等于要查找的值。如果当前层没有找到目标值，则继续向下一层查找。\n向下移动：如果在当前层没有找到目标值，则从当前节点向下移动到下一层的对应节点，继续查找。重复这个过程，直到到达最底层。\n在最底层查找：在最底层的链表中，继续向右移动，直到找到目标值或到达链表的末尾。如果在最底层找到了目标值，则查找成功；否则，查找失败.\n两个进程内存之间能互相读写吗 不能\n内存隔离：每个进程都有自己的虚拟内存空间，操作系统通过内存管理单元（MMU）确保进程只能访问自己的虚拟内存空间。不同进程的虚拟内存空间是独立的，不能直接相互访问。 权限保护：操作系统为每个进程分配了不同的权限级别，通常情况下，进程只能访问其权限范围内允许的资源，包括内存空间。进程之间的内存访问权限是严格限制的，以防止潜在的安全风险. 进程间通信（IPC）：虽然进程不能直接读写对方的内存，但可以通过进程间通信机制来交换数据。常见的进程间通信方式包括： 管道（Pipes）：允许进程之间通过管道进行数据传输，分为匿名管道和命名管道。 消息队列（Message Queues）：进程可以将消息发送到消息队列，其他进程可以从队列中读取消息。 信号（Signals）：用于进程之间的信号传递，可以通知进程发生某些事件。 共享内存（Shared Memory）：虽然共享内存允许进程共享同一块内存区域，但访问共享内存仍然需要通过特定的IPC机制来实现，并且需要同步机制来避免并发访问冲突. 套接字（Sockets）：用于进程之间的网络通信，可以实现进程间的双向数据传输。 调试和特殊权限：在某些情况下，具有特殊权限的进程（如调试器）可能可以访问其他进程的内存空间，但这需要明确的权限和操作系统的支持，且通常受到严格的限制和监管. 那b进程已经知道a进程他的内存地址了，那可以读写吗 不能\n虚拟内存机制：现代操作系统使用虚拟内存技术，每个进程都有自己的虚拟地址空间。进程 A 的内存地址是其虚拟地址空间中的地址，进程 B 无法直接通过这个地址访问物理内存。操作系统负责将虚拟地址映射到物理地址，而这个映射过程是受操作系统控制的，进程无法直接干预. 内存保护机制：操作系统通过内存管理单元（MMU）等硬件和软件机制，实现了内存保护。每个进程的内存空间被保护起来，不允许其他进程直接访问。即使进程 B 知道了进程 A 的某个虚拟地址，也无法通过这个地址访问进程 A 的内存，因为操作系统会阻止这种非法访问，防止进程之间的内存冲突和数据泄露. 权限限制：进程之间的内存访问受到严格的权限限制。进程 B 没有权限直接访问进程 A 的内存空间，即使它知道了地址。操作系统为进程分配了不同的权限级别，通常情况下，进程只能访问自己的内存空间和操作系统允许的共享资源。进程之间的内存访问权限是严格控制的，以确保系统的安全性和稳定性. 安全考虑：允许进程之间直接读写对方的内存会导致严重的安全隐患。恶意进程可能会利用这种能力去窃取其他进程的数据、篡改程序的执行流程等，从而对系统造成破坏。因此，操作系统设计了严格的隔离机制，确保进程之间的内存访问受到控制和监管，防止潜在的安全风险. 水平分表垂直分表的区别和应用场景 垂直分表：针对业务上字段比较多的大表进行的，一般是把业务宽表中比较独立的字段，或者不常用的字段拆分到单独的数据表中，是一种大表拆小表的模式。因为数据库它是以行为单位将数据加载到内存中，这样拆分以后核心表大多是访问频率较高的字段，而且字段长度也都较短，因而可以加载更多数据到内存中，减少磁盘IO，增加索引查询的命中率，进一步提升数据库性能。\n水平分表：是在同一个数据库内，把一张大数据量的表按一定规则，切分成多个结构完全相同表，而每个表只存原表的一部分数据。水平分表尽管拆分了表，但子表都还是在同一个数据库实例中，只是解决了单一表数据量过大的问题，并没有将拆分后的表分散到不同的机器上。还在竞争同一个物理机的CPU、内存、网络IO等，如果要想进一步提升性能，就需要将拆分后的表分散到不同的数据库中，达到分布式的效果。\ntcp调用send方法之后服务端就一定收到连接了吗 不会，只会发送到缓冲区，后续还需要通过tcp协议栈将这些数据通过网络传到目标主机\n成功时返回的是实际发送的字节数，这个值可能小于请求发送的字节数，因为TCP发送缓冲区可能已满。\n在TCP（传输控制协议）编程中，send 方法是一个用于从TCP套接字发送数据的函数。它通常在客户端或服务器端的网络编程中使用，以便将数据从一个进程发送到另一个进程。以下是 send 方法的一些关键点：\n功能： send 方法用于将数据从发送方的缓冲区发送到TCP套接字的发送缓冲区。TCP协议栈会负责将这些数据通过网络传输到目标主机. 它不保证数据立即被接收方接收，只是将数据放入TCP发送缓冲区，由TCP协议栈负责将数据可靠地传输到目标主机. 参数： socket：指定要发送数据的套接字描述符。这个套接字必须已经通过 connect 方法与目标主机建立了连接. buffer：指向要发送数据的缓冲区. length：要发送的数据长度（以字节为单位）. flags：控制发送行为的标志。常用的标志包括 MSG_DONTWAIT（非阻塞发送）等. 返回值： 成功时，返回实际发送的字节数。这个值可能小于请求发送的字节数，因为TCP发送缓冲区可能已满. 如果发生错误，返回-1，并设置错误码（例如，errno）以指示错误原因. 阻塞行为： 默认情况下，send 方法是阻塞的，这意味着如果TCP发送缓冲区已满，调用 send 方法的线程将被阻塞，直到有足够的空间可用. 可以通过设置套接字为非阻塞模式或使用 MSG_DONTWAIT 标志来改变这种行为. 可靠性： TCP是一个可靠的传输协议，它会确保数据的顺序性和完整性。即使 send 成功返回，也不能保证数据已经被接收方成功接收，只是表示数据已经被放入发送缓冲区. TCP协议栈会负责数据的重传、确认和顺序控制等，以确保数据的可靠传输. 应用场景： send 方法广泛应用于各种网络应用中，如HTTP服务器、FTP客户端、聊天应用等，用于发送请求、响应、消息等数据. tcp和udp是否可以绑定在同一端口 可以，传输层中端口号的作用就是为了区分同一个主机上不同的数据包，传输层有两个协议，分别为tcp和udp，在内核中是完全独立的两个模块，主机收到报文的时候可以根据ip层协议里的tcp或者是udp交给对应端口中的udp或者是tcp处理 虾皮卖家后端工程师一面\npython基础问题：\nPass continue break区别\n作用：pass 是一个空语句，它什么也不做。它通常用于占位，当语法上需要一个语句，但逻辑上不需要执行任何操作时，可以使用 pass。 Continue break不说了 new和init区别 都是魔术方法\nnew 在对象创建时被调用，负责创建对象实例。 init 在对象创建后被调用，负责初始化对象的属性。 python为什么效率慢，全局锁了解吗\n解释型语言的特性 Python 是一种解释型语言，代码在运行时需要逐行解释执行，而不是像编译型语言（如 C/C++）那样提前编译成机器码。这种逐行解释的方式虽然提供了灵活性，但也增加了运行时的开销，导致执行速度较慢。 全局解释器锁（GIL）的存在 Python 的 CPython 解释器引入了全局解释器锁（GIL），这是一种全局锁，用于保护解释器免受多线程并发访问的影响。GIL 的存在使得同一时刻只有一个线程能够执行 Python 字节码，即使在多核 CPU 环境下，也无法充分利用多核的计算能力。这在 CPU 密集型任务中尤为明显，成为性能瓶颈。 动态类型系统 Python 是一种动态类型语言，类型检查在运行时进行，而不是在编译时完成。这意味着每次变量操作都需要进行类型检查，增加了运行时的开销。 内存管理机制 Python 使用引用计数和垃圾回收机制进行内存管理。这些机制虽然方便，但在运行时需要进行额外的计算和管理，可能会导致性能下降。 如何优化 Python 的性能？ 尽管 Python 的执行效率受到一些限制，但可以通过以下方法优化性能： 使用多进程替代多线程\n由于 GIL 的限制，多线程在 CPU 密集型任务中效果不佳，但多进程可以绕过 GIL 的限制，充分利用多核 CPU。 异步编程\n对于 I/O 密集型任务，可以使用异步编程（如 asyncio）来提高效率。\n暂时无法在飞书文档外展示此内容\n进程线程区别 进程是操作系统资源分配的基本单位，而线程是任务调度和执行的基本单位 每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销 线程可以看作轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器，线程之间切换的开销小 进程中如果某个线程崩溃了，可能会导致整个进程都崩溃，而进程中的子进程崩溃，并不会影响其他进程。 系统在运行的时候会为每个进程分配不同的内存空间，而对线程而言，除了cpu外，系统不会为线程分配内存，线程组之间只能共享资源 没有线程的进程就可以看作是单线程，如果一个进程内有多个线程，则执行过程不是一条线的，而是包含多条线\n进程和线程切换的时候切换的是啥 进程切换主要包括整个进程的地址空间，全局变量，文件描述符等， 线程切换主要涉及到线程的堆栈，寄存器和程序计数器等，不涉及进程级别的资源，因此线程切换的开销较小\ncelery异步框架优点，异步队列呢 celery是一个强大的 分布式任务队列的异步处理框架，它可以让任务的执行完全脱离主程序，甚至可以被分配到其他主机上运行。我们通常使用它来实现异步任务（async task）和定时任务（crontab)。 异步任务：将耗时操作任务提交给Celery去异步执行，比如发送短信/邮件、消息推送、音视频处理等等 定时任务：定时执行某件事情，比如每天数据统计 https://blog.csdn.net/github_36665118/article/details/139177748?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_utm_term~default-1-139177748-blog-79481245.235^v43^pc_blog_bottom_relevance_base7\u0026spm=1001.2101.3001.4242.2\u0026utm_relevant_index=4 redis拿来做什么，为什么单线程快呢\nredis的消息队列怎么实现\n消息队列如何保证消费成功，如果消费过程中机器宕机了怎么办 消息消费了之后会有一个ack确认机制，可以手动确认也可以自动确认 providers.KafkaCorpGroupMsgConsumer.SetMessageHandleFunc(func(message *sarama.ConsumerMessage) { handleCorpGroupMsg(job_context.CreateJobContext(ctx), message) }) //providers.KafkaCorpGroupMsgConsumer.SetMessageHandleByHandFunc(handleCorpGroupMsgByHand)\n如果没有手动确认 Kafka 消息（即没有调用 session.MarkMessage(msg, \u0026ldquo;\u0026quot;)），Kafka 消费组将不会认为该消息已被成功处理。这会导致以下几种情况： 消息重复消费：Kafka 消费组会定期重试未确认的消息，导致这些消息可能被重复消费。 消费进度滞后：由于消息未被确认，Kafka 消费组的偏移量（offset）不会更新，导致消费进度滞后，可能会出现消息积压的情况。 资源浪费：重复处理相同的消息会浪费系统资源，增加不必要的负载。 因此，手动确认消息是确保消息只被处理一次并保持消费进度正常推进的关键步骤。\nmysql回表查询是啥 mysql索引分为主键索引和二级索引 主键索引里存放的是所有数据 二级索引存放的是主键 如果查询时需要走到二级索引，在二级索引里能查到那就不用回表，这叫做覆盖索引 如果要先在二级索引里拿到id，再通过这个id去到主键索引里面查找，那就叫回表\nredis延时队列怎么实现的 Redis 延迟机制： Redis 使用有序集合（Sorted Set）来管理延迟任务。每个任务根据其预定的执行时间（当前时间 + 延迟时间）作为分数（score）存入有序集合。 Redis 定期扫描有序集合，将到达预定时间的任务移至待处理队列中。\n项目qps如何\n线程协程区别\n有用过rpc框架吗 grpc，springcloudalibaba\n项目部署怎么操作，对docker熟悉吗\nlinux修改文件权限命令呢 Chmod\nSelect poll epoll讲一下\n项目中有涉及到分布式事务吗\n有性能优化的经验吗 mysql分表？https://blog.csdn.net/abckingaa/article/details/123026402\n水平分表如果有某些表数据过多，倾斜了怎么办 水平分表后出现数据倾斜是一个常见的问题，尤其是在分布式数据库和大数据处理场景中。以下是针对数据倾斜问题的解决方案：\n调整分表策略 如果某些表的数据量过多，可以重新评估分表策略，例如： 调整分表键：选择更均匀分布的字段作为分表键。 增加分表数量：通过增加分表的数量，将数据进一步分散。 数据打散 对于数据倾斜的表，可以对数据进行打散处理： 随机前缀：为倾斜的键添加随机前缀，将数据分散到多个分表。 二次聚合：将倾斜的键对应的数据拆分出来，单独处理后再进行聚合。 定期清理和迁移 对于数据量过大的表，可以定期进行清理和迁移： 数据归档：将历史数据归档到冷存储，减少活跃数据量。 数据迁移：将数据重新分配到其他分表，平衡数据分布。 监控和预警 建立监控机制，实时监控各分表的数据量和查询性能： 数据倾斜监控：通过监控工具检测数据倾斜情况，及时发现并处理。 自动调整：根据监控数据自动调整分表策略或触发数据迁移。 使用分布式锁 在处理数据倾斜时，可能会涉及跨表操作，此时可以使用分布式锁来保证操作的原子性。例如： Redis 分布式锁：使用 Redis 实现分布式锁，确保在数据迁移或清理时不会出现并发问题。 Zookeeper 分布式锁：利用 Zookeeper 的有序节点实现分布式锁，适用于需要强一致性的场景。 一致性哈希了解吗？ https://blog.csdn.net/a745233700/article/details/120814088?ops_request_misc=%257B%2522request%255Fid%2522%253A%25220d9b950c3cf6f3cf58370fc505be8ac6%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D\u0026request_id=0d9b950c3cf6f3cf58370fc505be8ac6\u0026biz_id=0\u0026utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-120814088-null-null.142^v101^pc_search_result_base5\u0026utm_term=%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C\u0026spm=1018.2226.3001.4187\n正常的哈希取模算法是hash（数据）%服务器数量，这样如果有服务器挂掉了整个都乱套了 一致性哈希是一个哈希环，算法为hash（数据/服务器）%2的32次方，每个服务器/数据都在哈希环的一个位置上面，数据被分配在顺时针往下的第一台服务器，这样可以避免有服务器挂掉之后所有的缓存都失效了。\nhash 环的倾斜在极端情况下，仍然有可能引起系统的崩溃，为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点，一个实际物理节点可以对应多个虚拟节点，虚拟节点越多，hash环上的节点就越多，缓存被均匀分布的概率就越大，hash环倾斜所带来的影响就越小，同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射。具体做法可以在服务器ip或主机名的后面增加编号来实现。 http和https的区别 Tls握手 ca证书 端口号80 443\nhttps是非对称加密还是对称加密的 [图片]\n对网关的了解，nginx呢\n网关有两种，一种是流量网关，一种是服务网关 流量网关和服务网关在系统整体架构中所处的位置如上图所示，流量网关（如Nignx）是指提供全局性的、与后端业务应用无关的策略，例如 HTTPS证书卸载、Web防火墙、全局流量监控等。而微服务网关（如Spring Cloud Gateway）是指与业务紧耦合的、提供单个业务域级别的策略，如服务治理、身份认证等。也就是说，流量网关负责南北向流量调度及安全防护，微服务网关负责东西向流量调度及服务治理。\n[图片] 原文链接：https://blog.csdn.net/a745233700/article/details/122917167 https://blog.csdn.net/a745233700/article/details/122917167\n卖家二面\nnginx怎么配置服务负载 春招投递\n官网投：\n点点互动 联科数通 Oppo tplink 作业帮 厦门亿联\nboss投： 桥介数物 小赢科技 tiktok实习 店匠科技 韶音科技 微派 宽德投资 taptap 北京万亿科技 游卡科技 美的 迅雷网络\n作业帮一面\n介绍一下你小鹅通做了什么项目\n轮询和异步流式响应怎么实现的，现在用的哪个\nredis消息队列用来干嘛\nredis做消息队列和kafka有什么区别\nkafka中的partition讲一下\n分表是怎么做的\n为什么要这样分，会不会有些表的对话记录过多\n如果要继续分成更多张表呢，怎么实现\n一致性哈希有什么优点呢\nredis分布式锁怎么实现的\nmysql的主从复制流程\ndockerfile文件有编写过吧\n限流有自己写过吗，具体怎么实现的滑动窗口\n链路追踪是怎么实现的捏\nRedis 的持久化\n两道算法\n1.有一个非负整数数组，如何拼接起来数字最小（只讲思路，不用实现） 对这个数组进行排序，排序方式为a+b\u0026gt;b+a\n2.螺旋矩阵（卡了一会儿秒了）\n总共一个小时（基本上都答上来了,两个小时后约二面）\n作业帮二面\nrag和普通的大模型有什么区别\nchunk分段怎么做的\n段落中的图片是一个file还是url\n如果是一个url的话那向量检索的时候怎么检索图片的意思呢\n如果一个小说中按段落分，但是一个段落当中达到了最大长度怎么办\n用的什么向量模型，为什么要用这个，有对比过吗\n重排模型的原理是啥，为什么要重排\n多路召回讲一下，检索是在哪检索？\n做题： 爬楼梯\n线程和协程的区别是什么 线程是cpu调度的基本单位，线程共享进程的内存空间，堆和全局变量\n协程属于用户态的轻量级线程，调度完全由程序控制，不需要内核参与。\n线程上下文的切换具体切换的是什么，流程是啥 上下文保存：具体保存了寄存器状态，程序计数器，堆栈指针等，然后切换调度器，调度器选择下一个需要执行的线程 选择好了之后就将该线程保存的上下文恢复\n协程呢，与线程有什么区别 协程上下文切换是在用户态的，由程序控制，而线程是在内核态的，无法主动控制。\n线程切换还需要保存寄存器，协程之间是共用寄存器的，只需要切换程序计数器和堆栈指针\n一个64核的gpu与16张4核的gpu，哪个更适合跑go服务，为什么 在比较一个64核的GPU与16张4核的GPU运行Go服务的资源利用率时，我们需要考虑几个关键因素：\n并行处理能力：Go语言以其并发处理能力而闻名，它使用goroutines来实现轻量级的线程管理。一个64核的GPU由于其核心数量较多，可以同时处理更多的goroutines，因此在理论上可以提供更高的并行处理能力。 资源分配与调度：单个64核的GPU在资源分配和调度上可能更为高效，因为它不需要在多个GPU之间分配任务，这样可以减少通信开销和潜在的资源浪费。 内存带宽与访问：通常，单个GPU的内存带宽和访问速度要优于多个GPU的组合，因为后者可能需要在不同GPU之间同步数据，这会增加延迟和降低整体性能。 扩展性与灵活性：16张4核的GPU提供了更高的扩展性和灵活性，可以根据需要增加或减少GPU数量，以适应不同的工作负载。 成本与能耗：从成本和能耗的角度来看，单个64核的GPU可能在长期运行中更为经济，因为它通常比16张4核的GPU组合更加节能，且维护成本可能更低。 综合考虑以上因素，一个64核的GPU在运行Go服务时，通常能够提供更高的资源利用率，因为它能够更有效地处理并发任务，减少通信开销，并提供更快的内存访问速度。然而，具体选择哪种配置，还需要根据实际应用场景、预算以及对扩展性和灵活性的需求来决定。 计算密集型和io密集型有什么区别，为什么go语言适合io密集型， 计算密集型任务：\n特点：这类任务主要消耗CPU资源，涉及大量的数学计算、数据分析和复杂算法处理。 资源需求：高性能的CPU是关键，内存速度和容量也会影响性能。 优化策略：优化算法、使用更高效的编程结构和并行计算可以提升性能。 I/O密集型任务： 特点：这类任务主要涉及大量的输入输出操作，如文件读写、网络通信和数据库交互。 资源需求：快速的存储设备（如SSD）、高带宽的网络连接和高效的I/O处理能力是重点。 优化策略：使用异步I/O操作、缓存机制和负载均衡可以提高效率。\n并发和并行有什么区别，计算密集型一般适合哪一种\n七牛实习的技术难点(这块没讲好，下次打算换成进程信号量打断了，不搞红包了)\n字节飞书一面（就25分钟）\ngolang的特点有啥\n并发能力强\n为什么golang适合io密集型，为什么并发能力强 Golang的并发能力主要得益于其内置的goroutine和channel机制。goroutine是一种轻量级的线程，创建和切换的开销极小，可以在单个进程中创建成千上万个goroutine而不会对性能造成明显影响。channel则提供了安全的通信机制，允许goroutine之间交换数据，避免了传统锁机制带来的复杂性和性能问题。\n对于IO密集型任务，如网络请求、文件读写等，Golang的并发模型能够显著提高性能。通过goroutine可以轻松实现异步处理，避免阻塞操作。例如，在处理多个文件读取任务时，可以为每个文件启动一个goroutine，并使用channel来收集结果。此外，Golang的select语句和time.Sleep函数可以实现非阻塞的异步操作。\n给一个golang适用于io密集型能力强的例子，里面各个协程之间是怎么调度的\nrag的整体链路说一下\n向量检索的原理是啥 余弦检索\n为什么要重排，如果不用混合检索，还需要重排吗\n其实是也需要的，两者的原理都不一样，重排模型是进一步的优化\n向量检索和重排都有打分，他们两个哪个置信度更高，重排模型的原理是啥呢\n重排置信度更高，重排使用了深度学习技术，利用了交叉编码器之类的东西去进行相关性判断\n假如说我有一个人与ai实时对话的场景，他的链路是啥\n如果一个人一直说话，那我服务端怎么办\n如果用websokcet连接的话，一个人说话他的数据是怎么传的，什么时候传，每一段的数据传的内容是什么\nredis消息队列怎么实现，和kafka的选型上有什么区别\n飞书二面\n前面三十分钟一直在问数字人项目架构\n调用外部接口出现过哪些问题，怎么解决的？\ntts用的啥\nTTS有对漏字做一些优化吗\ndeepseek有什么优势\nrag有没有做子问题的拆分\n大模型的注意力机制\nTransformer架构\n算法： 模拟rag做文本切分的场景： 用python从一篇英文文章中找到一个表格并且打印出来类似于这种： Hello i am bob No. A b c 1 10 20 30 2 40 50 60 Today is monday 3 70 80 90 who areyou 从上面这个段落中打印出 No. A b c 1 10 20 30 2 40 50 60 3 70 80 90\n飞书三面\n项目\n算法：最大正整数\n","date":"2025-06-16T22:19:07+08:00","permalink":"https://bobbydai.github.io/bobby_blog/p/0616-%E6%A0%A1%E6%8B%9B%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95%E8%BF%81%E7%A7%BB%E4%BA%8E%E9%A3%9E%E4%B9%A6%E6%96%87%E6%A1%A3/","title":"0616 校招面试记录（迁移于飞书文档）"},{"content":"2024-11-10： 最近有点迷茫，主要是因为工作还没确定，不知道往哪一个方向走，感觉还有好多东西要学的，但是又不知道从哪开始哈哈哈\n短期\n目前大概率是走ai后端方向了，公司目前考虑到两个选择：七牛云/4399，具体选哪家要等到七牛这边转正完开奖之后再决定。\n长期： 这两个方向要学的东西有很多：\n1.golang后端方向，java有时间可以看一下\n2.python后端开发也需要掌握一些知识，但大部分都是相通的\n3.python大模型应用+微调方向，这一块就更需要找资料自学，目前只对rag有一定的了解而已\n4.前端技能也需要了解一些\n5.爱好，学一门乐器+写歌？\n6.身心健康？\n一年内：以公司业务为主，让自己融入进去，能够解决大部分需求 一至三年:逐渐开始拓宽技术栈，跟着网上的高级开发+大模型方向学，并且应用到工作当中 三至五年：初步具备高级ai后端开发能力+跳入大厂 五年后：在大厂呆几年，结婚生子，累了就回家接班🤣\n伴随着开发自己的副业+读书+健身+兴趣爱好+博客+开源？\n短期目标：\n11-10至12-10 还是以面试为主，实习为辅\n12月之后可以走内部答辩转正，看一下七牛这边工资开的怎么样 然后定好工作，开始一边准备论文一边实习，实习到年前回来\n过年：主要精力放在毕业论文上面，这样回学校之后就轻松一些\n下学期：准备毕业相关要求+毕业论文+有空继续学习开发内容+出去玩哈哈哈\n2025-2-28： 总结一下这几个月，说实话对我自己来说真的很关键，今年年初四面之后收到了字节后端的offer，真的非常惊喜，当时感觉跟做梦一样，真的是美梦成真的感觉，之前对我来说高不可攀的公司突然就映入眼帘的感觉😂\n一开始想着就是一个月赚个18000就已经很不错的，结果字节开奖之后完全超出了预期，一个普普通通的双非本科生一毕业就拿40w，放在刚上大学的时候我也是不敢想的。还是感谢自己的努力的坚持，从前年10月国庆入门后端开发到现在以来，所有的付出都有了回报，一切都水到渠成了。中间肯定是有很多次的迷茫与艰辛，但最后一个offer通知书就是最好的回报，继续加油吧，这下生涯规划就得变了🐶\n2025-03-05\n下周五准备离职回深圳啦，这两周打算把python的相关技术栈都过一遍，还有个multi agent也过一遍，为到时候入职做准备。这边实习最近还是挺无聊的，主要是知道自己快走了，所以就没有派太多活，反正有活就干吧哈哈哈，走之前还是给领导留个好印象。\n另外这周还是再挑个地方出去玩一下，去附近再转转。\n准备离职了突然有点emo，在办公室没事做，但其实也挺舒服哈哈哈。感觉自己心态还是要放平呀，目前心情还是很复杂的，一方面自己上班了之后就大概率没太多时间了，生活可能也会慢慢归于平淡。另一方面对于当下也还有很多挑战，比如说毕业论文，上课，搬家等等。也还不清楚什么时候才有空去做自己想做的事情。只能说走一步看一步吧，继续加油。\n20205-03-16 上班第一天纯在打杂，感觉部门的技术栈似乎也不是很难，但还是有挺多不会的，主要是对python也不太熟，代码看得特别吃力，另外组里人确实很多，而且大家都特别忙 没空教你基本上。mentor人还不错，也是个五年的校招生，也还算比较ok啦。\n接下来的计划就是这周末把代码好好看看，打断点一步一步看，把整个项目搞明白，链路弄清楚。第一周主要是没适应强度，感觉经常没精神，干不动活，脑袋也乱乱的，下周开始要好好调整一下啦，多锻炼锻炼身体。部门的业务还是挺核心的，好好加油，还是先奋斗几年吧，后面机会多着呢。把身体锻炼好，成为一个优秀的男神好吧。\n","date":"2025-06-16T20:16:24+08:00","permalink":"https://bobbydai.github.io/bobby_blog/p/0616-%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/","title":"0616 学习计划"},{"content":"1-久违的回学校😄\n离职之后在家里躺了两周，为了准备考试终于重新回学校了哈哈哈。回学校突然发现有好多事要办，首先系统编程的实验和大作业就很烦，之前是直接抄舍友wmz的，今天突然发现里面截图的终端名字全是wmz，有点难蚌，感觉可能会露馅。感觉不能冒这个险，还是决定让老师撤回之后重新改一下再提交。明后天周末忙一下应该就好了吧。\n另外那个创新领航讲座也得再发一个邮件确定一下是不是完成了，否则万一到时候达不到毕业要求那就难蚌了。\n另外今天又发现了几首好歌，听的挺爽\n","date":"2025-06-16T20:04:49+08:00","permalink":"https://bobbydai.github.io/bobby_blog/p/0616-%E4%B9%85%E8%BF%9D%E7%9A%84%E5%9B%9E%E5%AD%A6%E6%A0%A1%E8%BF%81%E7%A7%BB%E4%BA%8Eday-one/","title":"0616 久违的回学校😄（迁移于day one）"},{"content":"对写日记的思考\n第一天开始使用这个软件写日记，也不知道这个Day One好不好用哈哈哈。之前写日记基本上都是拿笔在本子上写，这种方式的优点是不容易把自己的笔记弄丢，并且在我上大学工作之后，平时很少再去用笔写字了。重新在深夜重新提起笔来写日记就会让人有一种静下心来沉淀的感觉😂\n特别是在节奏很快的生活里， 很多当下一瞬间的快乐，美好与或好或坏的情绪都没有机会记录下来，时常会觉得特别可惜。毕竟我们人这一辈子来到世界上就是为去体验人生，在人生的过程中如果没有把自己的经历记录下来，可能当下是没有什么感觉。但是随着时间的流逝，这些记忆会慢慢的离我们远去。比如我现在对于之前的初中或者是高中很多事情都已经记不太清了。假如当时我有一些视频，照片，或者是日记本的话该有多好。举个例子，假如现在21岁的我再回去看以前的日记，肯定会有一些已经记不太清的事情，这个时候突然翻到了当时的日记就会让我有一种“咦，原来我还干过这些事情的想法”。\n我觉得这种感觉还是挺有意思的，也是挺有人生意义的。当自己变老的时候，我不想对自己的过去只是有一些模糊的印象，还是想明明白白的活着，知道自己这辈子做了哪些事，有哪些人生的关键节点，过得怎么样。更夸张的说，甚至当我离开这个世界的时候，可以把自己的日记等等的一些记录都放在墓碑的二维码里哈哈哈。这样才叫活的明白。但是这些内容还是得能够持久化的，得让后代去做备份，不能你mysql挂了，丢数据了就没了，那就白搞了。。。在之前四年的大学生活中，中间也有几次想把写日记的习惯重新捡起来，但每次坚持一个月就半途而废了。现在回过头看，感觉其实也挺正常的，首先当时自己在大学宿舍里面住，总感觉有点变扭，放不太开，有点为了融入这个群体而丢失自我的感觉。每天学习，玩游戏等安排似乎都不是自己最想要的生活。感觉这即跟大学的氛围有关，也跟自己内心放不开的心态有关。我自己还是比较喜欢出来工作之后的感觉，每天下班之后可以有一点自己的时间，做自己想做的事情，也没有别人的约束，也许是这种情况下自己才会去坚持写日记吧（也不好说哈哈哈，有可能工作太忙了也不行）哎呀，无论之前怎么样，反正从今天开始是要重新坚持了，首先第一步得确定写日记的载体，之前一直都是在笔记本上写，感觉这样效率还是太低了，比如说不能语音输入，并且没有视频，相片的载体，给人的感觉总还是会差一点。所以最后想着就还是用一个日记软件去记录比较好。付不付费都无所谓，功能是一定要齐全的。如果让我当产品经理的话，我觉得是需要做好分类，支持文字，音频，视频，图片等多媒体的形式。另外数据是可以导出备份的，因为我不想把自己的“终身大事”的稳定性托付给云厂商的数据库里面。万一哪一天来个地震，洪水啥的自然灾害，给机房直接搞没了咋办。所以自己还是得做备份的，可以写个脚本去批量的以excel之类的形式导出，将其放到自己的u盘里面做备份就好，毕竟数据量也不大，你就算写个几十年也没有多少数据量，花不了多少空间的。目前这个Day One软件给人的第一印象感觉还行，就是有些高级功能需要付费，其实付费还好，主要是还得要啥APP ID，还有银联的一些银行卡，贼麻烦。这些后面手机换苹果之后应该都要改的。等发工资再说吧，好好买部手机，并且将之前老手机里的照片，聊天记录啥的都整合一下，还有以前小学，初中，高中写的日记啥的也都要整合记录下来，这些都是迟早要干的事，等过几天找个时间干一下吧。第一篇日记，文笔并不是特别好，随便写写\n","date":"2025-06-16T18:04:12+08:00","permalink":"https://bobbydai.github.io/bobby_blog/p/0616-%E5%AF%B9%E5%86%99%E6%97%A5%E8%AE%B0%E7%9A%84%E6%80%9D%E8%80%83%E8%BF%81%E7%A7%BB%E4%BA%8Eday-one/","title":"0616 对写日记的思考（迁移于day one）"}]